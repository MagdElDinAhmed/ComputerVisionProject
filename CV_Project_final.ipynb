{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Local setup - no need for Google Drive mounting in VS Code\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# Set base directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 1: Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17 images in: /content/drive/MyDrive/Computer Vision Final/input\n",
      "Processing: 01.jpg\n",
      "  -> Checking for rotation/skew...\n",
      "  -> Rotated by -2.00° (reshape=False, mode=nearest; size preserved).\n",
      "  -> Laplacian Variance (noise sharpness): 1639.90\n",
      "  -> High noise detected (var=1639.90 > 100). Applied Gaussian blur.\n",
      "  -> Contrast Analysis: Darkest Ink Level=88.00, Contrast(StdDev)=29.83\n",
      "  -> Detection: Image is WASHED OUT (Ink is too light: 88.00 > 70)\n",
      "  -> Applying Contrast Stretching & Background Normalization...\n",
      "  -> Sobel Variance (edge sharpness): 10422.21\n",
      "  -> Edges sharp enough (var=10422.21 >= 50). Skipping sharpening.\n",
      "  -> Image Entropy (B&W check): 4.10\n",
      "  -> Image already B&W-like (entropy=4.10 <= 5.0). Skipping binary.\n",
      "  -> Saved enhanced to: /content/drive/MyDrive/Computer Vision Final/processed_3/01.jpg\n",
      "\n",
      "Processing: 02.jpg\n",
      "  -> Checking for rotation/skew...\n",
      "  -> Rotated by -2.00° (reshape=False, mode=nearest; size preserved).\n",
      "  -> Laplacian Variance (noise sharpness): 1952.76\n",
      "  -> High noise detected (var=1952.76 > 100). Applied Gaussian blur.\n",
      "  -> Contrast Analysis: Darkest Ink Level=74.00, Contrast(StdDev)=35.79\n",
      "  -> Detection: Image is WASHED OUT (Ink is too light: 74.00 > 70)\n",
      "  -> Applying Contrast Stretching & Background Normalization...\n",
      "  -> Sobel Variance (edge sharpness): 10836.98\n",
      "  -> Edges sharp enough (var=10836.98 >= 50). Skipping sharpening.\n",
      "  -> Image Entropy (B&W check): 4.30\n",
      "  -> Image already B&W-like (entropy=4.30 <= 5.0). Skipping binary.\n",
      "  -> Saved enhanced to: /content/drive/MyDrive/Computer Vision Final/processed_3/02.jpg\n",
      "\n",
      "Processing: 03.jpg\n",
      "  -> Checking for rotation/skew...\n",
      "  -> Laplacian Variance (noise sharpness): 1804.43\n",
      "  -> High noise detected (var=1804.43 > 100). Applied Gaussian blur.\n",
      "  -> Detection: Uneven shadows detected.\n",
      "  -> Contrast Analysis: Darkest Ink Level=81.00, Contrast(StdDev)=39.65\n",
      "  -> Detection: Image is WASHED OUT (Ink is too light: 81.00 > 70)\n",
      "  -> Applying Contrast Stretching & Background Normalization...\n",
      "  -> Sobel Variance (edge sharpness): 12470.84\n",
      "  -> Edges sharp enough (var=12470.84 >= 50). Skipping sharpening.\n",
      "  -> Image Entropy (B&W check): 4.33\n",
      "  -> Image already B&W-like (entropy=4.33 <= 5.0). Skipping binary.\n",
      "  -> Saved enhanced to: /content/drive/MyDrive/Computer Vision Final/processed_3/03.jpg\n",
      "\n",
      "Processing: 04.jpg\n",
      "  -> Checking for rotation/skew...\n",
      "  -> Starting Iterative Denoising...\n",
      "    -> Testing Kernel 3: Noise Ratio = 0.0034\n",
      "    -> Success! Noise below 0.005 using Kernel 3.\n",
      "  -> Laplacian Variance (noise sharpness): 2452.42\n",
      "  -> High noise detected (var=2452.42 > 100). Applied Gaussian blur.\n",
      "  -> Detection: Uneven shadows detected.\n",
      "  -> Contrast Analysis: Darkest Ink Level=107.00, Contrast(StdDev)=28.56\n",
      "  -> Detection: Image is WASHED OUT (Ink is too light: 107.00 > 70)\n",
      "  -> Applying Contrast Stretching & Background Normalization...\n",
      "  -> Sobel Variance (edge sharpness): 10650.30\n",
      "  -> Edges sharp enough (var=10650.30 >= 50). Skipping sharpening.\n",
      "  -> Image Entropy (B&W check): 2.43\n",
      "  -> Image already B&W-like (entropy=2.43 <= 5.0). Skipping binary.\n",
      "  -> Saved enhanced to: /content/drive/MyDrive/Computer Vision Final/processed_3/04.jpg\n",
      "\n",
      "Processing: 05.jpg\n",
      "  -> Checking for rotation/skew...\n",
      "  -> Laplacian Variance (noise sharpness): 892.35\n",
      "  -> High noise detected (var=892.35 > 100). Applied Gaussian blur.\n",
      "  -> Contrast Analysis: Darkest Ink Level=112.00, Contrast(StdDev)=25.91\n",
      "  -> Detection: Image is WASHED OUT (Ink is too light: 112.00 > 70)\n",
      "  -> Applying Contrast Stretching & Background Normalization...\n",
      "  -> Sobel Variance (edge sharpness): 8421.19\n",
      "  -> Edges sharp enough (var=8421.19 >= 50). Skipping sharpening.\n",
      "  -> Image Entropy (B&W check): 4.78\n",
      "  -> Image already B&W-like (entropy=4.78 <= 5.0). Skipping binary.\n",
      "  -> Saved enhanced to: /content/drive/MyDrive/Computer Vision Final/processed_3/05.jpg\n",
      "\n",
      "Processing: 06.jpg\n",
      "  -> Checking for rotation/skew...\n",
      "  -> Rotated by -4.00° (reshape=False, mode=nearest; size preserved).\n",
      "  -> Starting Iterative Denoising...\n",
      "    -> Testing Kernel 3: Noise Ratio = 0.0006\n",
      "    -> Success! Noise below 0.005 using Kernel 3.\n",
      "  -> Laplacian Variance (noise sharpness): 1860.13\n",
      "  -> High noise detected (var=1860.13 > 100). Applied Gaussian blur.\n",
      "  -> Detection: Uneven shadows detected.\n",
      "  -> Contrast Analysis: Darkest Ink Level=41.00, Contrast(StdDev)=43.05\n",
      "  -> Detection: Contrast looks okay.\n",
      "  -> Applying Contrast Stretching & Background Normalization...\n",
      "  -> Sobel Variance (edge sharpness): 14640.68\n",
      "  -> Edges sharp enough (var=14640.68 >= 50). Skipping sharpening.\n",
      "  -> Image Entropy (B&W check): 4.34\n",
      "  -> Image already B&W-like (entropy=4.34 <= 5.0). Skipping binary.\n",
      "  -> Saved enhanced to: /content/drive/MyDrive/Computer Vision Final/processed_3/06.jpg\n",
      "\n",
      "Processing: 07.jpg\n",
      "  -> Checking for rotation/skew...\n",
      "  -> Rotated by -2.00° (reshape=False, mode=nearest; size preserved).\n",
      "  -> Starting Iterative Denoising...\n",
      "    -> Testing Kernel 3: Noise Ratio = 0.0008\n",
      "    -> Success! Noise below 0.005 using Kernel 3.\n",
      "  -> Laplacian Variance (noise sharpness): 1303.02\n",
      "  -> High noise detected (var=1303.02 > 100). Applied Gaussian blur.\n",
      "  -> Detection: Image is too dark (Avg: 31.65)\n",
      "  -> Contrast Analysis: Darkest Ink Level=2.00, Contrast(StdDev)=16.69\n",
      "  -> Detection: Image is LOW CONTRAST (StdDev: 16.69 < 40)\n",
      "  -> Applying Contrast Stretching & Background Normalization...\n",
      "  -> Sobel Variance (edge sharpness): 11376.18\n",
      "  -> Edges sharp enough (var=11376.18 >= 50). Skipping sharpening.\n",
      "  -> Image Entropy (B&W check): 6.03\n",
      "  -> Applied adaptive binary thresholding (initial density: 0.5399).\n",
      "  -> Checking for interrupted Sudoku lines (optimized repair)...\n",
      "  -> Filtered contours (area>300): 115/352 total.\n",
      "  -> Detected 495 line segments.\n",
      "  -> H fragments: 11, V fragments: 16 (short thr: 37.0).\n",
      "  -> Applied median fallback for noise.\n",
      "  -> Triggered repair (27 > 8). Used kernels H:1x100, V:100x1.\n",
      "  -> Saved enhanced to: /content/drive/MyDrive/Computer Vision Final/processed_3/07.jpg\n",
      "\n",
      "Processing: 08.jpg\n",
      "  -> Checking for rotation/skew...\n",
      "  -> Laplacian Variance (noise sharpness): 8.74\n",
      "  -> Noise levels okay (var=8.74 <= 100). Skipping blur.\n",
      "  -> Detection: Image is too dark (Avg: 35.21)\n",
      "  -> Contrast Analysis: Darkest Ink Level=32.00, Contrast(StdDev)=1.36\n",
      "  -> Detection: Image is LOW CONTRAST (StdDev: 1.36 < 40)\n",
      "  -> Applying Contrast Stretching & Background Normalization...\n",
      "  -> Sobel Variance (edge sharpness): 7883.33\n",
      "  -> Edges sharp enough (var=7883.33 >= 50). Skipping sharpening.\n",
      "  -> Image Entropy (B&W check): 1.55\n",
      "  -> Image already B&W-like (entropy=1.55 <= 5.0). Skipping binary.\n",
      "  -> Saved enhanced to: /content/drive/MyDrive/Computer Vision Final/processed_3/08.jpg\n",
      "\n",
      "Processing: 09.jpg\n",
      "  -> Checking for rotation/skew...\n",
      "  -> Laplacian Variance (noise sharpness): 1397.43\n",
      "  -> High noise detected (var=1397.43 > 100). Applied Gaussian blur.\n",
      "  -> Detection: Uneven shadows detected.\n",
      "  -> Contrast Analysis: Darkest Ink Level=65.00, Contrast(StdDev)=31.54\n",
      "  -> Detection: Image is LOW CONTRAST (StdDev: 31.54 < 40)\n",
      "  -> Applying Contrast Stretching & Background Normalization...\n",
      "  -> Sobel Variance (edge sharpness): 12283.75\n",
      "  -> Edges sharp enough (var=12283.75 >= 50). Skipping sharpening.\n",
      "  -> Image Entropy (B&W check): 4.26\n",
      "  -> Image already B&W-like (entropy=4.26 <= 5.0). Skipping binary.\n",
      "  -> Saved enhanced to: /content/drive/MyDrive/Computer Vision Final/processed_3/09.jpg\n",
      "\n",
      "Processing: 10.jpg\n",
      "  -> Checking for rotation/skew...\n",
      "  -> Rotated by -3.00° (reshape=False, mode=nearest; size preserved).\n",
      "  -> Starting Iterative Denoising...\n",
      "    -> Testing Kernel 3: Noise Ratio = 0.2132\n",
      "    -> Testing Kernel 5: Noise Ratio = 0.0492\n",
      "    -> Testing Kernel 7: Noise Ratio = 0.0103\n",
      "    -> Testing Kernel 9: Noise Ratio = 0.0040\n",
      "    -> Success! Noise below 0.005 using Kernel 9.\n",
      "  -> Laplacian Variance (noise sharpness): 876.41\n",
      "  -> High noise detected (var=876.41 > 100). Applied Gaussian blur.\n",
      "  -> Detection: Uneven shadows detected.\n",
      "  -> Contrast Analysis: Darkest Ink Level=78.00, Contrast(StdDev)=29.11\n",
      "  -> Detection: Image is WASHED OUT (Ink is too light: 78.00 > 70)\n",
      "  -> Applying Contrast Stretching & Background Normalization...\n",
      "  -> Sobel Variance (edge sharpness): 5196.54\n",
      "  -> Edges sharp enough (var=5196.54 >= 50). Skipping sharpening.\n",
      "  -> Image Entropy (B&W check): 5.94\n",
      "  -> Applied adaptive binary thresholding (initial density: 0.5708).\n",
      "  -> Checking for interrupted Sudoku lines (optimized repair)...\n",
      "  -> Filtered contours (area>300): 43/765 total.\n",
      "  -> Detected 770 line segments.\n",
      "  -> H fragments: 40, V fragments: 41 (short thr: 37.0).\n",
      "  -> Applied median fallback for noise.\n",
      "  -> Triggered repair (81 > 8). Used kernels H:1x100, V:100x1.\n",
      "  -> Saved enhanced to: /content/drive/MyDrive/Computer Vision Final/processed_3/10.jpg\n",
      "\n",
      "Processing: 11.jpg\n",
      "  -> Checking for rotation/skew...\n",
      "  -> Laplacian Variance (noise sharpness): 1084.15\n",
      "  -> High noise detected (var=1084.15 > 100). Applied Gaussian blur.\n",
      "  -> Contrast Analysis: Darkest Ink Level=197.00, Contrast(StdDev)=19.87\n",
      "  -> Detection: Image is WASHED OUT (Ink is too light: 197.00 > 70)\n",
      "  -> Applying Contrast Stretching & Background Normalization...\n",
      "  -> Sobel Variance (edge sharpness): 9860.61\n",
      "  -> Edges sharp enough (var=9860.61 >= 50). Skipping sharpening.\n",
      "  -> Image Entropy (B&W check): 1.86\n",
      "  -> Image already B&W-like (entropy=1.86 <= 5.0). Skipping binary.\n",
      "  -> Saved enhanced to: /content/drive/MyDrive/Computer Vision Final/processed_3/11.jpg\n",
      "\n",
      "Processing: 12.jpg\n",
      "  -> Checking for rotation/skew...\n",
      "  -> Rotated by 24.00° (reshape=False, mode=nearest; size preserved).\n",
      "  -> Starting Iterative Denoising...\n",
      "    -> Testing Kernel 3: Noise Ratio = 0.0009\n",
      "    -> Success! Noise below 0.005 using Kernel 3.\n",
      "  -> Laplacian Variance (noise sharpness): 385.50\n",
      "  -> High noise detected (var=385.50 > 100). Applied Gaussian blur.\n",
      "  -> Detection: Uneven shadows detected.\n",
      "  -> Contrast Analysis: Darkest Ink Level=105.00, Contrast(StdDev)=27.67\n",
      "  -> Detection: Image is WASHED OUT (Ink is too light: 105.00 > 70)\n",
      "  -> Applying Contrast Stretching & Background Normalization...\n",
      "  -> Sobel Variance (edge sharpness): 7703.86\n",
      "  -> Edges sharp enough (var=7703.86 >= 50). Skipping sharpening.\n",
      "  -> Image Entropy (B&W check): 3.62\n",
      "  -> Image already B&W-like (entropy=3.62 <= 5.0). Skipping binary.\n",
      "  -> Saved enhanced to: /content/drive/MyDrive/Computer Vision Final/processed_3/12.jpg\n",
      "\n",
      "Processing: 13.jpg\n",
      "  -> Checking for rotation/skew...\n",
      "  -> Starting Iterative Denoising...\n",
      "    -> Testing Kernel 3: Noise Ratio = 0.0020\n",
      "    -> Success! Noise below 0.005 using Kernel 3.\n",
      "  -> Laplacian Variance (noise sharpness): 1675.49\n",
      "  -> High noise detected (var=1675.49 > 100). Applied Gaussian blur.\n",
      "  -> Detection: Uneven shadows detected.\n",
      "  -> Contrast Analysis: Darkest Ink Level=66.00, Contrast(StdDev)=48.02\n",
      "  -> Detection: Contrast looks okay.\n",
      "  -> Applying Contrast Stretching & Background Normalization...\n",
      "  -> Sobel Variance (edge sharpness): 14440.93\n",
      "  -> Edges sharp enough (var=14440.93 >= 50). Skipping sharpening.\n",
      "  -> Image Entropy (B&W check): 5.20\n",
      "  -> Applied adaptive binary thresholding (initial density: 0.6442).\n",
      "  -> Checking for interrupted Sudoku lines (optimized repair)...\n",
      "  -> Filtered contours (area>300): 111/686 total.\n",
      "  -> Detected 1144 line segments.\n",
      "  -> H fragments: 56, V fragments: 37 (short thr: 37.0).\n",
      "  -> Applied median fallback for noise.\n",
      "  -> Triggered repair (93 > 8). Used kernels H:1x100, V:100x1.\n",
      "  -> Saved enhanced to: /content/drive/MyDrive/Computer Vision Final/processed_3/13.jpg\n",
      "\n",
      "Processing: 14.jpg\n",
      "  -> Checking for rotation/skew...\n",
      "  -> Rotated by -2.00° (reshape=False, mode=nearest; size preserved).\n",
      "  -> Laplacian Variance (noise sharpness): 677.55\n",
      "  -> High noise detected (var=677.55 > 100). Applied Gaussian blur.\n",
      "  -> Detection: Uneven shadows detected.\n",
      "  -> Contrast Analysis: Darkest Ink Level=47.00, Contrast(StdDev)=49.70\n",
      "  -> Detection: Contrast looks okay.\n",
      "  -> Applying Contrast Stretching & Background Normalization...\n",
      "  -> Sobel Variance (edge sharpness): 6866.87\n",
      "  -> Edges sharp enough (var=6866.87 >= 50). Skipping sharpening.\n",
      "  -> Image Entropy (B&W check): 5.01\n",
      "  -> Applied adaptive binary thresholding (initial density: 0.6328).\n",
      "  -> Checking for interrupted Sudoku lines (optimized repair)...\n",
      "  -> Filtered contours (area>300): 41/210 total.\n",
      "  -> Detected 334 line segments.\n",
      "  -> H fragments: 5, V fragments: 16 (short thr: 37.0).\n",
      "  -> Applied median fallback for noise.\n",
      "  -> Triggered repair (21 > 8). Used kernels H:1x100, V:100x1.\n",
      "  -> Saved enhanced to: /content/drive/MyDrive/Computer Vision Final/processed_3/14.jpg\n",
      "\n",
      "Processing: 15 copy.jpg\n",
      "  -> Checking for rotation/skew...\n",
      "  -> Rotated by -32.00° (reshape=False, mode=nearest; size preserved).\n",
      "  -> Starting Iterative Denoising...\n",
      "    -> Testing Kernel 3: Noise Ratio = 0.0066\n",
      "    -> Testing Kernel 5: Noise Ratio = 0.0037\n",
      "    -> Success! Noise below 0.005 using Kernel 5.\n",
      "  -> Laplacian Variance (noise sharpness): 13348.93\n",
      "  -> High noise detected (var=13348.93 > 100). Applied Gaussian blur.\n",
      "  -> Detection: Uneven shadows detected.\n",
      "  -> Contrast Analysis: Darkest Ink Level=8.00, Contrast(StdDev)=59.34\n",
      "  -> Detection: Contrast looks okay.\n",
      "  -> Applying Contrast Stretching & Background Normalization...\n",
      "  -> Sobel Variance (edge sharpness): 19481.69\n",
      "  -> Edges sharp enough (var=19481.69 >= 50). Skipping sharpening.\n",
      "  -> Image Entropy (B&W check): 5.69\n",
      "  -> Applied adaptive binary thresholding (initial density: 0.6524).\n",
      "  -> Checking for interrupted Sudoku lines (optimized repair)...\n",
      "  -> Filtered contours (area>300): 90/651 total.\n",
      "  -> Detected 902 line segments.\n",
      "  -> H fragments: 9, V fragments: 15 (short thr: 37.0).\n",
      "  -> Applied median fallback for noise.\n",
      "  -> Triggered repair (24 > 8). Used kernels H:1x100, V:100x1.\n",
      "  -> Saved enhanced to: /content/drive/MyDrive/Computer Vision Final/processed_3/15 copy.jpg\n",
      "\n",
      "Processing: 15.jpg\n",
      "  -> Checking for rotation/skew...\n",
      "  -> Laplacian Variance (noise sharpness): 994.25\n",
      "  -> High noise detected (var=994.25 > 100). Applied Gaussian blur.\n",
      "  -> Contrast Analysis: Darkest Ink Level=142.00, Contrast(StdDev)=25.93\n",
      "  -> Detection: Image is WASHED OUT (Ink is too light: 142.00 > 70)\n",
      "  -> Applying Contrast Stretching & Background Normalization...\n",
      "  -> Sobel Variance (edge sharpness): 9012.01\n",
      "  -> Edges sharp enough (var=9012.01 >= 50). Skipping sharpening.\n",
      "  -> Image Entropy (B&W check): 3.56\n",
      "  -> Image already B&W-like (entropy=3.56 <= 5.0). Skipping binary.\n",
      "  -> Saved enhanced to: /content/drive/MyDrive/Computer Vision Final/processed_3/15.jpg\n",
      "\n",
      "Processing: 16.jpg\n",
      "  -> Checking for rotation/skew...\n",
      "  -> Rotated by -12.50° (reshape=False, mode=nearest; size preserved).\n",
      "  -> Starting Iterative Denoising...\n",
      "    -> Testing Kernel 3: Noise Ratio = 0.0055\n",
      "    -> Testing Kernel 5: Noise Ratio = 0.0014\n",
      "    -> Success! Noise below 0.005 using Kernel 5.\n",
      "  -> Laplacian Variance (noise sharpness): 429.63\n",
      "  -> High noise detected (var=429.63 > 100). Applied Gaussian blur.\n",
      "  -> Contrast Analysis: Darkest Ink Level=242.00, Contrast(StdDev)=9.62\n",
      "  -> Detection: Image is WASHED OUT (Ink is too light: 242.00 > 70)\n",
      "  -> Applying Contrast Stretching & Background Normalization...\n",
      "  -> Sobel Variance (edge sharpness): 13673.48\n",
      "  -> Edges sharp enough (var=13673.48 >= 50). Skipping sharpening.\n",
      "  -> Image Entropy (B&W check): 1.76\n",
      "  -> Image already B&W-like (entropy=1.76 <= 5.0). Skipping binary.\n",
      "  -> Saved enhanced to: /content/drive/MyDrive/Computer Vision Final/processed_3/16.jpg\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Your Exact: Needs Rotation Detection (Unchanged) ===\n",
    "\n",
    "def needs_rotation(gray):\n",
    "    edges = cv2.Canny(gray, 50, 150)\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi/180, 150)\n",
    "    if lines is None:\n",
    "        return False, 0\n",
    "    angles = []\n",
    "    for line in lines:\n",
    "        for rho, theta in line:\n",
    "            angle = (theta*180)/np.pi\n",
    "            if 20 < angle < 160:\n",
    "                angles.append(angle)\n",
    "    if angles:\n",
    "        main_angle = np.median(angles)\n",
    "        rot_angle = main_angle - 90 if main_angle > 45 else main_angle\n",
    "        return abs(rot_angle) > 2, rot_angle\n",
    "    return False, 0\n",
    "\n",
    "# === Rotate Function (Unchanged) ===\n",
    "\n",
    "def rotate(gray, angle, reshape=False, mode='nearest'):\n",
    "    h, w = gray.shape\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    flags = cv2.INTER_NEAREST if mode == 'nearest' else cv2.INTER_LINEAR\n",
    "    rotated = cv2.warpAffine(gray, M, (w, h), flags=flags, borderMode=cv2.BORDER_REPLICATE)\n",
    "    print(f\"  -> Rotated by {angle:.2f}° (reshape={reshape}, mode={mode}; size preserved).\")\n",
    "    return rotated\n",
    "\n",
    "# === 1. Detection: Washed Out / Faded Areas (Unchanged) ===\n",
    "\n",
    "def check_for_washout(img_gray, ink_threshold=70, contrast_threshold=40):\n",
    "    darkest_pixels_val = np.percentile(img_gray, 5)\n",
    "    std_dev = np.std(img_gray)\n",
    "    print(f\"  -> Contrast Analysis: Darkest Ink Level={darkest_pixels_val:.2f}, Contrast(StdDev)={std_dev:.2f}\")\n",
    "    if darkest_pixels_val > ink_threshold:\n",
    "        print(f\"  -> Detection: Image is WASHED OUT (Ink is too light: {darkest_pixels_val:.2f} > {ink_threshold})\")\n",
    "        return True\n",
    "    if std_dev < contrast_threshold:\n",
    "        print(f\"  -> Detection: Image is LOW CONTRAST (StdDev: {std_dev:.2f} < {contrast_threshold})\")\n",
    "        return True\n",
    "    print(\"  -> Detection: Contrast looks okay.\")\n",
    "    return False\n",
    "\n",
    "# === 2. Noise Measurement Helper (Unchanged) ===\n",
    "\n",
    "def get_noise_ratio(img_gray, noise_threshold=10):\n",
    "    denoised_ref = cv2.medianBlur(img_gray, 3)\n",
    "    diff = cv2.absdiff(img_gray, denoised_ref)\n",
    "    noise_mask = diff > noise_threshold\n",
    "    noise_pixel_count = np.sum(noise_mask)\n",
    "    return noise_pixel_count / img_gray.size\n",
    "\n",
    "# === Laplacian Variance (Unchanged) ===\n",
    "def get_laplacian_variance(img_gray, blur_size=3):\n",
    "    laplacian = cv2.Laplacian(img_gray, cv2.CV_64F, ksize=blur_size)\n",
    "    variance = laplacian.var()\n",
    "    print(f\"  -> Laplacian Variance (noise sharpness): {variance:.2f}\")\n",
    "    return variance\n",
    "\n",
    "# === Apply Gaussian Blur (Unchanged) ===\n",
    "def apply_gaussian_blur_if_needed(img_gray, variance_threshold=100):\n",
    "    variance = get_laplacian_variance(img_gray)\n",
    "    if variance > variance_threshold:\n",
    "        blurred = cv2.GaussianBlur(img_gray, (3, 3), sigmaX=0.5)\n",
    "        print(f\"  -> High noise detected (var={variance:.2f} > {variance_threshold}). Applied Gaussian blur.\")\n",
    "        return blurred, True\n",
    "    else:\n",
    "        print(f\"  -> Noise levels okay (var={variance:.2f} <= {variance_threshold}). Skipping blur.\")\n",
    "        return img_gray, False\n",
    "\n",
    "# === Sobel Variance (Unchanged) ===\n",
    "def get_sobel_variance(img_gray, ksize=3):\n",
    "    sobelx = cv2.Sobel(img_gray, cv2.CV_64F, 1, 0, ksize=ksize)\n",
    "    sobely = cv2.Sobel(img_gray, cv2.CV_64F, 0, 1, ksize=ksize)\n",
    "    sobel_combined = np.sqrt(sobelx**2 + sobely**2)\n",
    "    variance = sobel_combined.var()\n",
    "    print(f\"  -> Sobel Variance (edge sharpness): {variance:.2f}\")\n",
    "    return variance\n",
    "\n",
    "# === Apply Unsharp Sharpen (Unchanged) ===\n",
    "def apply_unsharp_sharpen_if_needed(img_gray, variance_threshold=50, amount=1.0):\n",
    "    variance = get_sobel_variance(img_gray)\n",
    "    if variance < variance_threshold:\n",
    "        blurred = cv2.GaussianBlur(img_gray, (5, 5), sigmaX=1.0)\n",
    "        sharpened = cv2.addWeighted(img_gray, 1.5, blurred, -0.5, 0)\n",
    "        print(f\"  -> Soft edges detected (var={variance:.2f} < {variance_threshold}). Applied unsharp sharpening (amount={amount}).\")\n",
    "        return sharpened, True\n",
    "    else:\n",
    "        print(f\"  -> Edges sharp enough (var={variance:.2f} >= {variance_threshold}). Skipping sharpening.\")\n",
    "        return img_gray, False\n",
    "\n",
    "# === Binary Thresholding (Unchanged) ===\n",
    "def apply_binary_thresholding_if_needed(img_gray, entropy_threshold=5.0, block_size=11, C=2):\n",
    "    hist = cv2.calcHist([img_gray], [0], None, [256], [0, 256])\n",
    "    entropy = -np.sum((hist / hist.sum()) * np.log2(hist / hist.sum() + 1e-10))\n",
    "    print(f\"  -> Image Entropy (B&W check): {entropy:.2f}\")\n",
    "\n",
    "    if entropy > entropy_threshold:\n",
    "        binary = cv2.adaptiveThreshold(img_gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                       cv2.THRESH_BINARY_INV, block_size, C)\n",
    "        dark_pixels = np.sum(binary == 0)\n",
    "        total_pixels = binary.size\n",
    "        density = dark_pixels / total_pixels\n",
    "        if density < 0.05 or density > 0.5:\n",
    "            _, binary = cv2.threshold(img_gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        print(f\"  -> Applied adaptive binary thresholding (initial density: {density:.4f}).\")\n",
    "        return binary, True\n",
    "    else:\n",
    "        print(f\"  -> Image already B&W-like (entropy={entropy:.2f} <= {entropy_threshold}). Skipping binary.\")\n",
    "        return img_gray, False\n",
    "\n",
    "# === Optimized: Repair Lines (Unchanged from Prior) ===\n",
    "\n",
    "def repair_sudoku_lines_if_needed(binary_img, fragment_threshold=8, min_length=30):\n",
    "    print(\"  -> Checking for interrupted Sudoku lines (optimized repair)...\")\n",
    "\n",
    "    contours, _ = cv2.findContours(binary_img, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    line_mask = np.zeros_like(binary_img)\n",
    "    large_contours_count = 0\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 300:\n",
    "            cv2.drawContours(line_mask, [cnt], -1, 255, -1)\n",
    "            large_contours_count += 1\n",
    "    binary_lines = cv2.bitwise_and(binary_img, line_mask)\n",
    "    print(f\"  -> Filtered contours (area>300): {large_contours_count}/{len(contours)} total.\")\n",
    "\n",
    "    dil_kernel = np.ones((3, 3), np.uint8)\n",
    "    binary_lines_dil = cv2.dilate(binary_lines, dil_kernel, iterations=1)\n",
    "\n",
    "    edges = cv2.Canny(binary_lines_dil, 50, 150, apertureSize=3)\n",
    "    lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi/180, threshold=25,\n",
    "                            minLineLength=min_length, maxLineGap=30)\n",
    "\n",
    "    if lines is None:\n",
    "        lines = np.array([])\n",
    "        print(\"  -> No lines detected by Hough.\")\n",
    "\n",
    "    print(f\"  -> Detected {len(lines)} line segments.\")\n",
    "\n",
    "    fragments = 0\n",
    "    img_h, img_w = binary_img.shape\n",
    "    expected_len = max(img_h, img_w) / 9\n",
    "    short_threshold = expected_len / 3\n",
    "    h_fragments = 0\n",
    "    v_fragments = 0\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        length = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "        if abs(x2 - x1) >= abs(y2 - y1) and abs(x2 - x1) > 15:\n",
    "            if length < short_threshold:\n",
    "                h_fragments += 1\n",
    "        elif abs(y2 - y1) >= abs(x2 - x1) and abs(y2 - y1) > 15:\n",
    "            if length < short_threshold:\n",
    "                v_fragments += 1\n",
    "    fragments = h_fragments + v_fragments\n",
    "    print(f\"  -> H fragments: {h_fragments}, V fragments: {v_fragments} (short thr: {short_threshold:.1f}).\")\n",
    "\n",
    "    if fragments > fragment_threshold:\n",
    "        h_kernel_size = max(1, img_w // 10)\n",
    "        v_kernel_size = max(1, img_h // 10)\n",
    "        h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, h_kernel_size))\n",
    "        repaired_h = cv2.morphologyEx(binary_lines, cv2.MORPH_CLOSE, h_kernel, iterations=3)\n",
    "\n",
    "        v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (v_kernel_size, 1))\n",
    "        repaired_v = cv2.morphologyEx(repaired_h, cv2.MORPH_CLOSE, v_kernel, iterations=3)\n",
    "\n",
    "        open_kernel = np.ones((3, 3), np.uint8)\n",
    "        repaired = cv2.morphologyEx(repaired_v, cv2.MORPH_OPEN, open_kernel, iterations=2)\n",
    "        repaired = cv2.dilate(repaired, np.ones((3, 3), np.uint8), iterations=2)\n",
    "\n",
    "        if np.sum(repaired > 200) / repaired.size > 0.015:\n",
    "            repaired = cv2.medianBlur(repaired, 3)\n",
    "            print(\"  -> Applied median fallback for noise.\")\n",
    "\n",
    "        repaired = cv2.bitwise_or(repaired, binary_img)\n",
    "\n",
    "        print(f\"  -> Triggered repair ({fragments} > {fragment_threshold}). Used kernels H:1x{h_kernel_size}, V:{v_kernel_size}x1.\")\n",
    "        return repaired, True\n",
    "    else:\n",
    "        print(f\"  -> Low fragments ({fragments} <= {fragment_threshold}). Skipping repair.\")\n",
    "        return binary_img, False\n",
    "\n",
    "# === New: Extract Sudoku Board (Adapted from Reference) ===\n",
    "\n",
    "def extract_sudoku_board(img_color, img_gray, img_binary=None, epsilon=0.015):\n",
    "    \"\"\"\n",
    "    Adapted: Detects largest quad contour on binary/gray; orders corners; warps to top-down rectangle.\n",
    "    Uses reference logic: medianBlur + adaptive thresh; max dist dims; clockwise order.\n",
    "    Returns warped color/gray/binary (if provided); skips if no 4 points.\n",
    "    \"\"\"\n",
    "    print(\"  -> Extracting Sudoku board (perspective warp)...\")\n",
    "\n",
    "    # Prep: Blur + adaptive on gray (as reference)\n",
    "    blur = cv2.medianBlur(img_gray, 3)\n",
    "    thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                   cv2.THRESH_BINARY_INV, 11, 3)\n",
    "\n",
    "    # Contours: Largest external\n",
    "    cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    if not cnts:\n",
    "        print(\"  -> No contours found. Skipping board extraction.\")\n",
    "        return img_color, img_gray, img_binary or img_gray, False\n",
    "\n",
    "    # Largest contour approx\n",
    "    c = cnts[0]\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, epsilon * peri, True)\n",
    "\n",
    "    if len(approx) != 4:\n",
    "        print(f\"  -> Largest contour approx has {len(approx)} points (need 4). Skipping board extraction.\")\n",
    "        return img_color, img_gray, img_binary or img_gray, False\n",
    "\n",
    "    # Order corners (reference: clockwise TL, TR, BR, BL via sums/diffs)\n",
    "    corners = approx.reshape(4, 2)\n",
    "    s = corners.sum(axis=1)\n",
    "    diff = np.diff(corners, axis=1)\n",
    "    top_l = corners[np.argmin(s)]\n",
    "    top_r = corners[np.argmin(diff)]\n",
    "    bottom_r = corners[np.argmax(s)]\n",
    "    bottom_l = corners[np.argmax(diff)]\n",
    "    ordered_corners = np.array([top_l, top_r, bottom_r, bottom_l], dtype=\"float32\")\n",
    "\n",
    "    # Dimensions (max width/height from distances)\n",
    "    width_a = np.sqrt(((bottom_r[0] - bottom_l[0]) ** 2) + ((bottom_r[1] - bottom_l[1]) ** 2))\n",
    "    width_b = np.sqrt(((top_r[0] - top_l[0]) ** 2) + ((top_r[1] - top_l[1]) ** 2))\n",
    "    width = max(int(width_a), int(width_b))\n",
    "\n",
    "    height_a = np.sqrt(((top_r[0] - bottom_r[0]) ** 2) + ((top_r[1] - bottom_r[1]) ** 2))\n",
    "    height_b = np.sqrt(((top_l[0] - bottom_l[0]) ** 2) + ((top_l[1] - bottom_l[1]) ** 2))\n",
    "    height = max(int(height_a), int(height_b))\n",
    "\n",
    "    # Dst points: TL, TR, BR, BL\n",
    "    dimensions = np.array([[0, 0], [width - 1, 0], [width - 1, height - 1], [0, height - 1]], dtype=\"float32\")\n",
    "\n",
    "    # Transform matrix\n",
    "    matrix = cv2.getPerspectiveTransform(ordered_corners, dimensions)\n",
    "\n",
    "    # Warp color, gray, binary (if avail)\n",
    "    warped_color = cv2.warpPerspective(img_color, matrix, (width, height))\n",
    "    warped_gray = cv2.warpPerspective(img_gray, matrix, (width, height))\n",
    "    if img_binary is not None:\n",
    "        warped_binary = cv2.warpPerspective(img_binary, matrix, (width, height))\n",
    "    else:\n",
    "        warped_binary = warped_gray\n",
    "\n",
    "    print(f\"  -> Board extracted: {warped_color.shape[:2]} (w:{width}, h:{height}).\")\n",
    "    return warped_color, warped_gray, warped_binary, True\n",
    "\n",
    "# === 3. Iterative Denoising (Unchanged) ===\n",
    "\n",
    "def iterative_denoise(img_gray, max_kernel=19, target_ratio=0.01):\n",
    "    kernel = 3\n",
    "    best_img = img_gray.copy()\n",
    "    print(\"  -> Starting Iterative Denoising...\")\n",
    "\n",
    "    while kernel <= max_kernel:\n",
    "        temp_img = cv2.medianBlur(img_gray, kernel)\n",
    "        current_ratio = get_noise_ratio(temp_img)\n",
    "        print(f\"    -> Testing Kernel {kernel}: Noise Ratio = {current_ratio:.4f}\")\n",
    "\n",
    "        if current_ratio < target_ratio:\n",
    "            print(f\"    -> Success! Noise below {target_ratio} using Kernel {kernel}.\")\n",
    "            return temp_img, kernel\n",
    "\n",
    "        best_img = temp_img\n",
    "        kernel += 2\n",
    "\n",
    "    print(f\"    -> Warning: Reached Max Kernel ({max_kernel}) without fully cleaning. Using result anyway.\")\n",
    "    return best_img, max_kernel\n",
    "\n",
    "# === 4. Lighting Fix (Unchanged) ===\n",
    "\n",
    "def check_if_lighting_fix_needed(img_gray, dark_threshold=110, shadow_variance=60):\n",
    "    avg_brightness = np.mean(img_gray)\n",
    "    if avg_brightness < dark_threshold:\n",
    "        print(f\"  -> Detection: Image is too dark (Avg: {avg_brightness:.2f})\")\n",
    "        return True\n",
    "\n",
    "    thumbnail = cv2.resize(img_gray, (20, 20))\n",
    "    min_val = np.min(thumbnail)\n",
    "    max_val = np.max(thumbnail)\n",
    "\n",
    "    if (max_val - min_val) > (255 - dark_threshold) and min_val < shadow_variance:\n",
    "        print(\"  -> Detection: Uneven shadows detected.\")\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def fix_lighting_and_shadows(img_gray):\n",
    "    print(\"  -> Applying Contrast Stretching & Background Normalization...\")\n",
    "    dilated = cv2.dilate(img_gray, np.ones((7, 7), np.uint8))\n",
    "    bg_img = cv2.medianBlur(dilated, 21)\n",
    "    diff_img = 255 - cv2.absdiff(img_gray, bg_img)\n",
    "    norm_img = diff_img.copy()\n",
    "    cv2.normalize(diff_img, norm_img, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.8, tileGridSize=(10,10))\n",
    "    return clahe.apply(norm_img)\n",
    "\n",
    "# === 5. Updated Pipeline (With Board Extraction as Final Step) ===\n",
    "\n",
    "def process_image_pipeline(image_path, output_folder):\n",
    "    img_color = cv2.imread(image_path)\n",
    "    if img_color is None:\n",
    "        print(f\"Error: Could not read {image_path}\")\n",
    "        return\n",
    "\n",
    "    current_gray = cv2.cvtColor(img_color, cv2.COLOR_BGR2GRAY)\n",
    "    actions_taken = []\n",
    "\n",
    "    # --- STEP 0: ROTATION ---\n",
    "    print(\"  -> Checking for rotation/skew...\")\n",
    "    rotated, angle = needs_rotation(current_gray)\n",
    "    if rotated:\n",
    "        current_gray = rotate(current_gray, angle, reshape=False, mode='nearest')\n",
    "        img_color = cv2.cvtColor(current_gray, cv2.COLOR_GRAY2BGR)  # Update color too\n",
    "        actions_taken.append(\"rotated\")\n",
    "\n",
    "    # --- STEP A: NOISE & BLUR ---\n",
    "    initial_noise = get_noise_ratio(current_gray)\n",
    "    if initial_noise > 0.01:\n",
    "        current_gray, final_k = iterative_denoise(current_gray, max_kernel=19, target_ratio=0.005)\n",
    "        img_color = cv2.cvtColor(current_gray, cv2.COLOR_GRAY2BGR)\n",
    "        actions_taken.append(f\"denoisedK{final_k}\")\n",
    "\n",
    "    current_gray, blurred_flag = apply_gaussian_blur_if_needed(current_gray, variance_threshold=100)\n",
    "    if blurred_flag:\n",
    "        img_color = cv2.cvtColor(current_gray, cv2.COLOR_GRAY2BGR)\n",
    "        actions_taken.append(\"gaussian_blur\")\n",
    "\n",
    "    # --- STEP B: LIGHTING & WASHOUT ---\n",
    "    is_dark_or_shadowed = check_if_lighting_fix_needed(current_gray)\n",
    "    is_washed_out = check_for_washout(current_gray)\n",
    "    if is_dark_or_shadowed or is_washed_out:\n",
    "        current_gray = fix_lighting_and_shadows(current_gray)\n",
    "        img_color = cv2.cvtColor(current_gray, cv2.COLOR_GRAY2BGR)\n",
    "        actions_taken.append(\"fixed_contrast\")\n",
    "\n",
    "    # --- STEP D: SHARPENING ---\n",
    "    current_gray, sharpen_flag = apply_unsharp_sharpen_if_needed(current_gray, variance_threshold=50)\n",
    "    if sharpen_flag:\n",
    "        img_color = cv2.cvtColor(current_gray, cv2.COLOR_GRAY2BGR)\n",
    "        actions_taken.append(\"sharpened\")\n",
    "\n",
    "    # --- STEP E: BINARY & REPAIR ---\n",
    "    binary_img, binary_flag = apply_binary_thresholding_if_needed(current_gray, entropy_threshold=5.0)\n",
    "    if binary_flag:\n",
    "        actions_taken.append(\"binary\")\n",
    "        repaired_img, repair_flag = repair_sudoku_lines_if_needed(binary_img, fragment_threshold=8)\n",
    "        if repair_flag:\n",
    "            binary_img = repaired_img\n",
    "            actions_taken.append(\"lines_repaired\")\n",
    "\n",
    "    # --- STEP G: SAVE (Enhanced + Binary + Board) ---\n",
    "\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    filename = os.path.basename(image_path)\n",
    "    enhanced_path = os.path.join(output_folder, f\"{filename}\")\n",
    "    cv2.imwrite(enhanced_path, current_gray)\n",
    "\n",
    "    print(f\"  -> Saved enhanced to: {enhanced_path}\\n\")\n",
    "\n",
    "def process_path(path, output_folder,\n",
    "                 exts=(\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")):\n",
    "    \"\"\"\n",
    "    If `path` is a file -> process that file.\n",
    "    If `path` is a directory -> process all images inside (non-recursive).\n",
    "    \"\"\"\n",
    "    if os.path.isfile(path):\n",
    "        print(f\"Processing single file: {os.path.basename(path)}\")\n",
    "        process_image_pipeline(path, output_folder)\n",
    "        return\n",
    "\n",
    "    if not os.path.isdir(path):\n",
    "        print(f\"Error: {path} is neither a file nor a directory\")\n",
    "        return\n",
    "\n",
    "    # Directory case: collect all images\n",
    "    all_files = os.listdir(path)  # or glob(os.path.join(path, \"*\"))[web:2][web:10]\n",
    "    image_files = [\n",
    "        f for f in all_files\n",
    "        if f.lower().endswith(exts)\n",
    "    ]\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"No image files found in: {path}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Found {len(image_files)} images in: {path}\")\n",
    "    for fname in sorted(image_files):\n",
    "        file_path = os.path.join(path, fname)\n",
    "        print(f\"Processing: {fname}\")\n",
    "        process_image_pipeline(file_path, output_folder)\n",
    "\n",
    "\n",
    "# --- RUNNER (Updated for 16.jpg) ---\n",
    "\n",
    "\n",
    "input_dir = \"/content/drive/MyDrive/Computer Vision Final/input\"\n",
    "output_dir = \"/content/drive/MyDrive/Computer Vision Final/processed_3/\"\n",
    "\n",
    "process_path(input_dir, output_dir)\n",
    "\n",
    "\n",
    "# Updated Helper (Added lines_repaired variants)\n",
    "def show_processed_images(folder, file_list, actions=[\"original_\", \"denoised_\", \"gaussian_blur_\", \"fixed_contrast_\", \"denoisedK5_fixed_contrast_gaussian_blur_\", \"sharpened_\", \"binary_\", \"lines_repaired_\"]):\n",
    "    plt.figure(figsize=(15, 5 * len(file_list)))\n",
    "    img_id = 1\n",
    "    for fname in file_list:\n",
    "        for action in actions:\n",
    "            full_path = os.path.join(folder, f\"{action}{os.path.basename(fname)}\")\n",
    "            if os.path.exists(full_path):\n",
    "                img = cv2.imread(full_path, cv2.IMREAD_GRAYSCALE)\n",
    "                plt.subplot(len(file_list), len(actions), img_id)\n",
    "                plt.imshow(img, cmap='gray')\n",
    "                plt.title(f\"{os.path.basename(fname)}\\n[{action[:-1]}]\" if action != \"original_\" else f\"{os.path.basename(fname)}\\n[Original]\")\n",
    "                plt.axis('off')\n",
    "                img_id += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 2: Detect board frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17 images in directory: /content/drive/MyDrive/Computer Vision Final/processed_3\n",
      "\n",
      "============================================================\n",
      "Processing: 01.jpg\n",
      "============================================================\n",
      "Detected 157 line segments\n",
      "✓ Saved Hough lines: /content/drive/MyDrive/Computer Vision Final/warped_batch/01_hough_lines.jpg\n",
      "Corners detected: [[37.0, 45.0], [960.0, 45.0], [960.0, 952.0], [37.0, 952.0]]\n",
      "✓ Saved detected corners: /content/drive/MyDrive/Computer Vision Final/warped_batch/01_corners.jpg\n",
      "✓ Perspective transform successful! Output size: (923, 923)\n",
      "✓ Processing complete for 01.jpg\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing: 02.jpg\n",
      "============================================================\n",
      "Detected 181 line segments\n",
      "✓ Saved Hough lines: /content/drive/MyDrive/Computer Vision Final/warped_batch/02_hough_lines.jpg\n",
      "Corners detected: [[34.0, 55.0], [959.0, 55.0], [959.0, 948.0], [34.0, 948.0]]\n",
      "✓ Saved detected corners: /content/drive/MyDrive/Computer Vision Final/warped_batch/02_corners.jpg\n",
      "✓ Perspective transform successful! Output size: (925, 925)\n",
      "✓ Processing complete for 02.jpg\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing: 03.jpg\n",
      "============================================================\n",
      "Detected 126 line segments\n",
      "✓ Saved Hough lines: /content/drive/MyDrive/Computer Vision Final/warped_batch/03_hough_lines.jpg\n",
      "Corners detected: [[43.0, 7.0], [951.0, 7.0], [951.0, 931.0], [43.0, 931.0]]\n",
      "✓ Saved detected corners: /content/drive/MyDrive/Computer Vision Final/warped_batch/03_corners.jpg\n",
      "✓ Perspective transform successful! Output size: (924, 924)\n",
      "✓ Processing complete for 03.jpg\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing: 04.jpg\n",
      "============================================================\n",
      "Detected 134 line segments\n",
      "✓ Saved Hough lines: /content/drive/MyDrive/Computer Vision Final/warped_batch/04_hough_lines.jpg\n",
      "Corners detected: [[48.0, 40.0], [973.0, 40.0], [973.0, 959.0], [48.0, 959.0]]\n",
      "✓ Saved detected corners: /content/drive/MyDrive/Computer Vision Final/warped_batch/04_corners.jpg\n",
      "✓ Perspective transform successful! Output size: (925, 925)\n",
      "✓ Processing complete for 04.jpg\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing: 05.jpg\n",
      "============================================================\n",
      "Detected 138 line segments\n",
      "✓ Saved Hough lines: /content/drive/MyDrive/Computer Vision Final/warped_batch/05_hough_lines.jpg\n",
      "Corners detected: [[59.0, 76.0], [932.0, 76.0], [932.0, 935.0], [59.0, 935.0]]\n",
      "✓ Saved detected corners: /content/drive/MyDrive/Computer Vision Final/warped_batch/05_corners.jpg\n",
      "✓ Perspective transform successful! Output size: (873, 873)\n",
      "✓ Processing complete for 05.jpg\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing: 06.jpg\n",
      "============================================================\n",
      "Detected 133 line segments\n",
      "✓ Saved Hough lines: /content/drive/MyDrive/Computer Vision Final/warped_batch/06_hough_lines.jpg\n",
      "Corners detected: [[97.0, 75.0], [971.0, 75.0], [971.0, 909.0], [97.0, 909.0]]\n",
      "✓ Saved detected corners: /content/drive/MyDrive/Computer Vision Final/warped_batch/06_corners.jpg\n",
      "✓ Perspective transform successful! Output size: (874, 874)\n",
      "✓ Processing complete for 06.jpg\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing: 07.jpg\n",
      "============================================================\n",
      "Detected 150 line segments\n",
      "✓ Saved Hough lines: /content/drive/MyDrive/Computer Vision Final/warped_batch/07_hough_lines.jpg\n",
      "Corners detected: [[95.0, 63.0], [962.0, 63.0], [962.0, 966.0], [95.0, 966.0]]\n",
      "✓ Saved detected corners: /content/drive/MyDrive/Computer Vision Final/warped_batch/07_corners.jpg\n",
      "✓ Perspective transform successful! Output size: (903, 903)\n",
      "✓ Processing complete for 07.jpg\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing: 08.jpg\n",
      "============================================================\n",
      "Detected 163 line segments\n",
      "✓ Saved Hough lines: /content/drive/MyDrive/Computer Vision Final/warped_batch/08_hough_lines.jpg\n",
      "Corners detected: [[47.0, 36.0], [943.0, 36.0], [943.0, 955.0], [47.0, 955.0]]\n",
      "✓ Saved detected corners: /content/drive/MyDrive/Computer Vision Final/warped_batch/08_corners.jpg\n",
      "✓ Perspective transform successful! Output size: (919, 919)\n",
      "✓ Processing complete for 08.jpg\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing: 09.jpg\n",
      "============================================================\n",
      "Detected 165 line segments\n",
      "✓ Saved Hough lines: /content/drive/MyDrive/Computer Vision Final/warped_batch/09_hough_lines.jpg\n",
      "Corners detected: [[47.0, 42.0], [965.0, 42.0], [965.0, 935.0], [47.0, 935.0]]\n",
      "✓ Saved detected corners: /content/drive/MyDrive/Computer Vision Final/warped_batch/09_corners.jpg\n",
      "✓ Perspective transform successful! Output size: (918, 918)\n",
      "✓ Processing complete for 09.jpg\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing: 10.jpg\n",
      "============================================================\n",
      "Detected 88 line segments\n",
      "✓ Saved Hough lines: /content/drive/MyDrive/Computer Vision Final/warped_batch/10_hough_lines.jpg\n",
      "Corners detected: [[41.0, 21.0], [971.0, 21.0], [971.0, 921.0], [41.0, 921.0]]\n",
      "✓ Saved detected corners: /content/drive/MyDrive/Computer Vision Final/warped_batch/10_corners.jpg\n",
      "✓ Perspective transform successful! Output size: (930, 930)\n",
      "✓ Processing complete for 10.jpg\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing: 11.jpg\n",
      "============================================================\n",
      "Detected 87 line segments\n",
      "✓ Saved Hough lines: /content/drive/MyDrive/Computer Vision Final/warped_batch/11_hough_lines.jpg\n",
      "Corners detected: [[32.0, 16.0], [984.0, 16.0], [984.0, 966.0], [32.0, 966.0]]\n",
      "✓ Saved detected corners: /content/drive/MyDrive/Computer Vision Final/warped_batch/11_corners.jpg\n",
      "✓ Perspective transform successful! Output size: (952, 952)\n",
      "✓ Processing complete for 11.jpg\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing: 12.jpg\n",
      "============================================================\n",
      "Detected 222 line segments\n",
      "✓ Saved Hough lines: /content/drive/MyDrive/Computer Vision Final/warped_batch/12_hough_lines.jpg\n",
      "Corners detected: [[155.0, 163.0], [1099.0, 163.0], [1099.0, 1101.0], [155.0, 1101.0]]\n",
      "✓ Saved detected corners: /content/drive/MyDrive/Computer Vision Final/warped_batch/12_corners.jpg\n",
      "✓ Perspective transform successful! Output size: (944, 944)\n",
      "✓ Processing complete for 12.jpg\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing: 13.jpg\n",
      "============================================================\n",
      "Detected 218 line segments\n",
      "✓ Saved Hough lines: /content/drive/MyDrive/Computer Vision Final/warped_batch/13_hough_lines.jpg\n",
      "Corners detected: [[42.0, 37.0], [974.0, 37.0], [974.0, 954.0], [42.0, 954.0]]\n",
      "✓ Saved detected corners: /content/drive/MyDrive/Computer Vision Final/warped_batch/13_corners.jpg\n",
      "✓ Perspective transform successful! Output size: (932, 932)\n",
      "✓ Processing complete for 13.jpg\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing: 14.jpg\n",
      "============================================================\n",
      "Detected 153 line segments\n",
      "✓ Saved Hough lines: /content/drive/MyDrive/Computer Vision Final/warped_batch/14_hough_lines.jpg\n",
      "Corners detected: [[76.0, 40.0], [978.0, 40.0], [978.0, 943.0], [76.0, 943.0]]\n",
      "✓ Saved detected corners: /content/drive/MyDrive/Computer Vision Final/warped_batch/14_corners.jpg\n",
      "✓ Perspective transform successful! Output size: (903, 903)\n",
      "✓ Processing complete for 14.jpg\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing: 15 copy.jpg\n",
      "============================================================\n",
      "WARNING: No lines detected for 15 copy.jpg\n",
      "\n",
      "============================================================\n",
      "Processing: 15.jpg\n",
      "============================================================\n",
      "Detected 152 line segments\n",
      "✓ Saved Hough lines: /content/drive/MyDrive/Computer Vision Final/warped_batch/15_hough_lines.jpg\n",
      "Corners detected: [[41.0, 45.0], [966.0, 45.0], [966.0, 984.0], [41.0, 984.0]]\n",
      "✓ Saved detected corners: /content/drive/MyDrive/Computer Vision Final/warped_batch/15_corners.jpg\n",
      "✓ Perspective transform successful! Output size: (939, 939)\n",
      "✓ Processing complete for 15.jpg\n",
      "\n",
      "\n",
      "============================================================\n",
      "Processing: 16.jpg\n",
      "============================================================\n",
      "Detected 82 line segments\n",
      "✓ Saved Hough lines: /content/drive/MyDrive/Computer Vision Final/warped_batch/16_hough_lines.jpg\n",
      "Corners detected: [[144.0, 136.0], [1052.0, 136.0], [1052.0, 1042.0], [144.0, 1042.0]]\n",
      "✓ Saved detected corners: /content/drive/MyDrive/Computer Vision Final/warped_batch/16_corners.jpg\n",
      "✓ Perspective transform successful! Output size: (908, 908)\n",
      "✓ Processing complete for 16.jpg\n",
      "\n",
      "\n",
      "============================================================\n",
      "BATCH PROCESSING COMPLETE\n",
      "============================================================\n",
      "Total images: 17\n",
      "Successful: 16\n",
      "Failed: 1\n",
      "\n",
      "Failed images:\n",
      "  - 15 copy.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def process_sudoku_image(input_path, output_folder, save_intermediates=False):\n",
    "    \"\"\"\n",
    "    Process a Sudoku image: detect grid, apply perspective transform, and save result.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_path : str\n",
    "        Path to input Sudoku image\n",
    "    output_folder : str\n",
    "        Folder to save processed images\n",
    "    save_intermediates : bool\n",
    "        Whether to save intermediate processing steps (default: False)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    bool : True if successful, False otherwise\n",
    "    \"\"\"\n",
    "\n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Get input filename\n",
    "    filename = os.path.basename(input_path)\n",
    "    name_without_ext = os.path.splitext(filename)[0]\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing: {filename}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 1. LOAD + PREPROCESSING\n",
    "    # -------------------------\n",
    "    img = cv2.imread(input_path)\n",
    "    if img is None:\n",
    "        print(f\"ERROR: Could not read image from {input_path}\")\n",
    "        return False\n",
    "\n",
    "    original = img.copy()\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Adaptive threshold\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        blurred, 255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        11, 2\n",
    "    )\n",
    "\n",
    "    if save_intermediates:\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"{name_without_ext}_01_threshold.jpg\"), thresh)\n",
    "\n",
    "    # -------------------------\n",
    "    # 2. MORPHOLOGICAL OPS\n",
    "    # -------------------------\n",
    "\n",
    "    # Extract horizontal lines\n",
    "    horizontal = thresh.copy()\n",
    "    h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))\n",
    "    horizontal = cv2.erode(horizontal, h_kernel, iterations=1)\n",
    "    horizontal = cv2.dilate(horizontal, h_kernel, iterations=1)\n",
    "\n",
    "    # Extract vertical lines\n",
    "    vertical = thresh.copy()\n",
    "    v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))\n",
    "    vertical = cv2.erode(vertical, v_kernel, iterations=1)\n",
    "    vertical = cv2.dilate(vertical, v_kernel, iterations=1)\n",
    "\n",
    "    # Combine them to get grid mask\n",
    "    grid_mask = cv2.addWeighted(horizontal, 0.5, vertical, 0.5, 0)\n",
    "\n",
    "    if save_intermediates:\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"{name_without_ext}_02_horizontal.jpg\"), horizontal)\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"{name_without_ext}_03_vertical.jpg\"), vertical)\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"{name_without_ext}_04_grid_mask.jpg\"), grid_mask)\n",
    "\n",
    "    # -------------------------\n",
    "    # 3. HOUGH TRANSFORM\n",
    "    # -------------------------\n",
    "\n",
    "    lines = cv2.HoughLinesP(\n",
    "        grid_mask,\n",
    "        rho=1,\n",
    "        theta=np.pi/180,\n",
    "        threshold=150,\n",
    "        minLineLength=100,\n",
    "        maxLineGap=10\n",
    "    )\n",
    "\n",
    "    if lines is None:\n",
    "        print(f\"WARNING: No lines detected for {filename}\")\n",
    "        return False\n",
    "\n",
    "    print(f\"Detected {len(lines)} line segments\")\n",
    "\n",
    "    # ALWAYS save Hough lines visualization\n",
    "    hough_img = original.copy()\n",
    "    for line in lines:\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv2.line(hough_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    hough_output_path = os.path.join(output_folder, f\"{name_without_ext}_hough_lines.jpg\")\n",
    "    cv2.imwrite(hough_output_path, hough_img)\n",
    "    print(f\"✓ Saved Hough lines: {hough_output_path}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 4. HELPER FUNCTIONS\n",
    "    # -------------------------\n",
    "\n",
    "    def cluster_lines(lines_list, threshold=20):\n",
    "        \"\"\"Cluster similar lines together\"\"\"\n",
    "        if len(lines_list) == 0:\n",
    "            return []\n",
    "\n",
    "        lines_list = sorted(lines_list)\n",
    "        clusters = []\n",
    "        current_cluster = [lines_list[0]]\n",
    "\n",
    "        for line in lines_list[1:]:\n",
    "            if line - current_cluster[-1] < threshold:\n",
    "                current_cluster.append(line)\n",
    "            else:\n",
    "                clusters.append(int(np.mean(current_cluster)))\n",
    "                current_cluster = [line]\n",
    "        clusters.append(int(np.mean(current_cluster)))\n",
    "        return clusters\n",
    "\n",
    "    def find_grid_corners_from_hough(lines, img_shape):\n",
    "        \"\"\"Find the four corners of Sudoku grid from Hough lines\"\"\"\n",
    "        h_lines = []\n",
    "        v_lines = []\n",
    "\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            angle = np.abs(np.arctan2(y2 - y1, x2 - x1) * 180 / np.pi)\n",
    "\n",
    "            # Horizontal lines\n",
    "            if angle < 10 or angle > 170:\n",
    "                y_avg = (y1 + y2) // 2\n",
    "                h_lines.append(y_avg)\n",
    "            # Vertical lines\n",
    "            elif 80 < angle < 100:\n",
    "                x_avg = (x1 + x2) // 2\n",
    "                v_lines.append(x_avg)\n",
    "\n",
    "        # Cluster lines to get main grid lines\n",
    "        h_clusters = cluster_lines(h_lines, threshold=20)\n",
    "        v_clusters = cluster_lines(v_lines, threshold=20)\n",
    "\n",
    "        if len(h_clusters) < 2 or len(v_clusters) < 2:\n",
    "            return None\n",
    "\n",
    "        # Get outer boundaries (first and last lines)\n",
    "        top = h_clusters[0]\n",
    "        bottom = h_clusters[-1]\n",
    "        left = v_clusters[0]\n",
    "        right = v_clusters[-1]\n",
    "\n",
    "        # Create corner points\n",
    "        corners = np.array([\n",
    "            [left, top],\n",
    "            [right, top],\n",
    "            [right, bottom],\n",
    "            [left, bottom]\n",
    "        ], dtype=np.float32)\n",
    "\n",
    "        return corners\n",
    "\n",
    "    def order_points(pts):\n",
    "        \"\"\"Order points in clockwise order starting from top-left\"\"\"\n",
    "        rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "\n",
    "        s = pts.sum(axis=1)\n",
    "        rect[0] = pts[np.argmin(s)]\n",
    "        rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "        diff = np.diff(pts, axis=1)\n",
    "        rect[1] = pts[np.argmin(diff)]\n",
    "        rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "        return rect\n",
    "\n",
    "    def perspective_transform(image, corners):\n",
    "        \"\"\"Apply perspective transform to get top-down view\"\"\"\n",
    "        rect = order_points(corners)\n",
    "        (tl, tr, br, bl) = rect\n",
    "\n",
    "        widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "        widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "        maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "        heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "        heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "        maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "        size = max(maxWidth, maxHeight)\n",
    "\n",
    "        dst = np.array([\n",
    "            [0, 0],\n",
    "            [size - 1, 0],\n",
    "            [size - 1, size - 1],\n",
    "            [0, size - 1]\n",
    "        ], dtype=\"float32\")\n",
    "\n",
    "        M = cv2.getPerspectiveTransform(rect, dst)\n",
    "        warped = cv2.warpPerspective(image, M, (size, size))\n",
    "\n",
    "        return warped, M\n",
    "\n",
    "    # -------------------------\n",
    "    # 5. FIND CORNERS\n",
    "    # -------------------------\n",
    "\n",
    "    sudoku_corners = find_grid_corners_from_hough(lines, original.shape)\n",
    "\n",
    "    # Fallback: Try contour detection\n",
    "    if sudoku_corners is None:\n",
    "        print(\"Hough method failed, trying contour detection...\")\n",
    "        contours, _ = cv2.findContours(\n",
    "            grid_mask,\n",
    "            cv2.RETR_EXTERNAL,\n",
    "            cv2.CHAIN_APPROX_SIMPLE\n",
    "        )\n",
    "\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "        for cnt in contours:\n",
    "            perimeter = cv2.arcLength(cnt, True)\n",
    "            approx = cv2.approxPolyDP(cnt, 0.02 * perimeter, True)\n",
    "\n",
    "            if len(approx) == 4:\n",
    "                sudoku_corners = approx.reshape(4, 2).astype(np.float32)\n",
    "                print(\"Using contour corners as fallback\")\n",
    "                break\n",
    "\n",
    "    if sudoku_corners is None:\n",
    "        print(f\"ERROR: Could not detect grid corners for {filename}\")\n",
    "        return False\n",
    "\n",
    "    print(f\"Corners detected: {sudoku_corners.tolist()}\")\n",
    "\n",
    "    # ALWAYS save corners visualization\n",
    "    corners_img = original.copy()\n",
    "    ordered = order_points(sudoku_corners)\n",
    "\n",
    "    # Draw corner points with numbers\n",
    "    for i, corner in enumerate(ordered):\n",
    "        cv2.circle(corners_img, tuple(corner.astype(int)), 15, (0, 0, 255), -1)\n",
    "        cv2.putText(corners_img, str(i), tuple(corner.astype(int)),\n",
    "                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "\n",
    "    # Draw lines connecting corners (bounding box)\n",
    "    for i in range(4):\n",
    "        pt1 = tuple(ordered[i].astype(int))\n",
    "        pt2 = tuple(ordered[(i+1)%4].astype(int))\n",
    "        cv2.line(corners_img, pt1, pt2, (0, 255, 0), 3)\n",
    "\n",
    "    corners_output_path = os.path.join(output_folder, f\"{name_without_ext}_corners.jpg\")\n",
    "    cv2.imwrite(corners_output_path, corners_img)\n",
    "    print(f\"✓ Saved detected corners: {corners_output_path}\")\n",
    "\n",
    "    # -------------------------\n",
    "    # 6. PERSPECTIVE TRANSFORM\n",
    "    # -------------------------\n",
    "\n",
    "    try:\n",
    "        warped, transform_matrix = perspective_transform(original, sudoku_corners)\n",
    "        warped_gray, _ = perspective_transform(gray, sudoku_corners)\n",
    "        print(f\"✓ Perspective transform successful! Output size: {warped.shape[:2]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: Perspective transform failed: {e}\")\n",
    "        return False\n",
    "\n",
    "    # Save other intermediate steps if requested\n",
    "    if save_intermediates:\n",
    "        # Additional intermediate visualizations already saved above\n",
    "        pass\n",
    "\n",
    "    print(f\"✓ Processing complete for {filename}\\n\")\n",
    "    return True\n",
    "\n",
    "\n",
    "def process_sudoku_batch(input_source, output_folder, save_intermediates=False,\n",
    "                         exts=(\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")):\n",
    "    \"\"\"\n",
    "    Process multiple Sudoku images in batch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_source : list[str] or str\n",
    "        - If list: list of input image paths\n",
    "        - If str and is a file: single image path\n",
    "        - If str and is a directory: all images in that directory will be processed\n",
    "    output_folder : str\n",
    "        Folder to save all processed images\n",
    "    save_intermediates : bool\n",
    "        Whether to save intermediate processing steps\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict : Summary of results with success/failure counts\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize input_source into a list of paths\n",
    "    if isinstance(input_source, str):\n",
    "        if os.path.isdir(input_source):  # directory case [web:28][web:29]\n",
    "            all_files = os.listdir(input_source)\n",
    "            input_paths = [\n",
    "                os.path.join(input_source, f)\n",
    "                for f in all_files\n",
    "                if f.lower().endswith(exts)\n",
    "            ]\n",
    "            input_paths.sort()\n",
    "            print(f\"Found {len(input_paths)} images in directory: {input_source}\")\n",
    "        elif os.path.isfile(input_source):\n",
    "            input_paths = [input_source]\n",
    "        else:\n",
    "            print(f\"ERROR: {input_source} is neither a file nor a directory\")\n",
    "            return {\n",
    "                'successful': [],\n",
    "                'failed': [],\n",
    "                'total': 0\n",
    "            }\n",
    "    else:\n",
    "        # Assume it's already an iterable of paths (original behavior)\n",
    "        input_paths = list(input_source)\n",
    "\n",
    "    results = {\n",
    "        'successful': [],\n",
    "        'failed': [],\n",
    "        'total': len(input_paths)\n",
    "    }\n",
    "\n",
    "    for input_path in input_paths:\n",
    "        if not os.path.exists(input_path):\n",
    "            print(f\"WARNING: File not found: {input_path}\")\n",
    "            results['failed'].append(input_path)\n",
    "            continue\n",
    "\n",
    "        success = process_sudoku_image(input_path, output_folder, save_intermediates)\n",
    "\n",
    "        if success:\n",
    "            results['successful'].append(input_path)\n",
    "        else:\n",
    "            results['failed'].append(input_path)\n",
    "\n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"BATCH PROCESSING COMPLETE\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Total images: {results['total']}\")\n",
    "    print(f\"Successful: {len(results['successful'])}\")\n",
    "    print(f\"Failed: {len(results['failed'])}\")\n",
    "\n",
    "    if results['failed']:\n",
    "        print(\"\\nFailed images:\")\n",
    "        for path in results['failed']:\n",
    "            print(f\"  - {os.path.basename(path)}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# USAGE EXAMPLES\n",
    "# -------------------------\n",
    "\n",
    "\n",
    "\n",
    "input_dir = \"/content/drive/MyDrive/Computer Vision Final/processed_3\"\n",
    "output_directory = \"/content/drive/MyDrive/Computer Vision Final/warped_batch/\"\n",
    "\n",
    "results = process_sudoku_batch(input_dir, output_directory, save_intermediates=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 3: Reduce to a squre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[REUSE] 01.jpg: accepted (areaRatio=0.85, aspect=1.02)\n",
      "[OK] 01.jpg: reuse=True hough_used=False warped=(450, 450)\n",
      "[REUSE] 02.jpg: accepted (areaRatio=0.84, aspect=1.03)\n",
      "[OK] 02.jpg: reuse=True hough_used=False warped=(450, 450)\n",
      "[REUSE] 03.jpg: accepted (areaRatio=0.86, aspect=0.99)\n",
      "[OK] 03.jpg: reuse=True hough_used=False warped=(450, 450)\n",
      "[REUSE] 04.jpg: accepted (areaRatio=0.87, aspect=1.00)\n",
      "[OK] 04.jpg: reuse=True hough_used=False warped=(450, 450)\n",
      "[REUSE] 05.jpg: accepted (areaRatio=0.77, aspect=1.01)\n",
      "[OK] 05.jpg: reuse=True hough_used=False warped=(450, 450)\n",
      "[REUSE] 06.jpg: accepted (areaRatio=0.75, aspect=1.04)\n",
      "[OK] 06.jpg: reuse=True hough_used=False warped=(450, 450)\n",
      "[REUSE] 07.jpg: accepted (areaRatio=0.80, aspect=0.96)\n",
      "[OK] 07.jpg: reuse=True hough_used=False warped=(450, 450)\n",
      "[REUSE] 08.jpg: accepted (areaRatio=0.84, aspect=0.98)\n",
      "[OK] 08.jpg: reuse=True hough_used=False warped=(450, 450)\n",
      "[REUSE] 09.jpg: accepted (areaRatio=0.84, aspect=1.03)\n",
      "[OK] 09.jpg: reuse=True hough_used=False warped=(450, 450)\n",
      "[REUSE] 10.jpg: accepted (areaRatio=0.85, aspect=1.03)\n",
      "[OK] 10.jpg: reuse=True hough_used=False warped=(450, 450)\n",
      "[REUSE] 11.jpg: accepted (areaRatio=0.92, aspect=1.00)\n",
      "[OK] 11.jpg: reuse=True hough_used=False warped=(450, 450)\n",
      "[REUSE] 12.jpg: accepted (areaRatio=0.54, aspect=1.01)\n",
      "[OK] 12.jpg: reuse=True hough_used=False warped=(450, 450)\n",
      "[REUSE] 13.jpg: accepted (areaRatio=0.87, aspect=1.01)\n",
      "[OK] 13.jpg: reuse=True hough_used=False warped=(450, 450)\n",
      "[REUSE] 14.jpg: accepted (areaRatio=0.83, aspect=1.00)\n",
      "[OK] 14.jpg: reuse=True hough_used=False warped=(450, 450)\n",
      "[HOUGH-NO-LINES] 15 copy.jpg\n",
      "[NO-ROTATE] 15 copy.jpg: correction=0.00 reliable=False count=0\n",
      "[LINES] 15 copy.jpg: accepted (areaRatio=1.00, aspect=1.00, spacing_ok=True)\n",
      "[OK] 15 copy.jpg: reuse=False hough_used=False warped=(450, 450)\n",
      "[REUSE] 15.jpg: accepted (areaRatio=0.89, aspect=0.98)\n",
      "[OK] 15.jpg: reuse=True hough_used=False warped=(450, 450)\n",
      "[REUSE] 16.jpg: accepted (areaRatio=0.58, aspect=1.00)\n",
      "[OK] 16.jpg: reuse=True hough_used=False warped=(450, 450)\n",
      "\n",
      "Batch refinement complete: success=17, failed=0, total=17\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "REFINE_INPUT_DIR = '/content/drive/MyDrive/Computer Vision Final/processed_3'\n",
    "REFINE_OUTPUT_DIR = '/content/drive/MyDrive/Computer Vision Final/final_square'\n",
    "PREVIOUS_OUTPUT_DIR = '/content/drive/MyDrive/Computer Vision Final/warped_batch'\n",
    "os.makedirs(REFINE_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "TARGET_SIZE = 450\n",
    "MIN_LINE_LENGTH_FACTOR = 0.4\n",
    "GRID_EXPECTED_LINES = 10\n",
    "ROTATION_MIN_CORRECTION = 2.0\n",
    "ROTATION_MAX_CORRECTION = 12.0\n",
    "VERTICAL_MIN_COUNT = 6\n",
    "VERTICAL_STD_MAX = 2.5\n",
    "UNIFORMITY_RATIO_LIMIT = 2.2  # slightly stricter than spacing_uniform fallback\n",
    "\n",
    "# -----------------------------\n",
    "# DETECT GRID LINES (morphology + Hough)\n",
    "# -----------------------------\n",
    "def detect_grid_lines(gray):\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    thresh = cv2.adaptiveThreshold(blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY_INV, 11, 2)\n",
    "    h = thresh.copy(); v = thresh.copy()\n",
    "    h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))\n",
    "    v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))\n",
    "    h = cv2.erode(h, h_kernel, iterations=1); h = cv2.dilate(h, h_kernel, iterations=1)\n",
    "    v = cv2.erode(v, v_kernel, iterations=1); v = cv2.dilate(v, v_kernel, iterations=1)\n",
    "    grid_mask = cv2.addWeighted(h, 0.5, v, 0.5, 0)\n",
    "    h_val, w_val = gray.shape\n",
    "    min_line_len = int(min(h_val, w_val) * MIN_LINE_LENGTH_FACTOR)\n",
    "    lines = cv2.HoughLinesP(grid_mask, 1, np.pi/180, 120, minLineLength=min_line_len, maxLineGap=15)\n",
    "    if lines is None:\n",
    "        lines = cv2.HoughLinesP(thresh, 1, np.pi/180, 150, minLineLength=min_line_len, maxLineGap=20)\n",
    "    return lines, grid_mask, thresh\n",
    "\n",
    "# -----------------------------\n",
    "# CLASSIFY LINES\n",
    "# -----------------------------\n",
    "def classify_lines(lines):\n",
    "    horizontal_positions, vertical_positions = [], []\n",
    "    if lines is None: return horizontal_positions, vertical_positions, []\n",
    "    vertical_angles = []\n",
    "    for seg in lines:\n",
    "        x1,y1,x2,y2 = seg[0]\n",
    "        dx, dy = x2 - x1, y2 - y1\n",
    "        ang = np.degrees(np.arctan2(dy, dx))\n",
    "        abs_ang = abs(ang)\n",
    "        if abs_ang < 10 or abs_ang > 170:\n",
    "            horizontal_positions.append((y1 + y2)//2)\n",
    "        elif 80 < abs_ang < 100:\n",
    "            vertical_positions.append((x1 + x2)//2)\n",
    "            if ang < 0: ang += 180\n",
    "            vertical_angles.append(ang)\n",
    "    return horizontal_positions, vertical_positions, vertical_angles\n",
    "\n",
    "# -----------------------------\n",
    "# ROTATION ESTIMATION\n",
    "# -----------------------------\n",
    "def estimate_rotation(vertical_angles):\n",
    "    if len(vertical_angles) < VERTICAL_MIN_COUNT:\n",
    "        return 0.0, False\n",
    "    arr = np.array(vertical_angles)\n",
    "    mean_ang = arr.mean(); std_ang = arr.std()\n",
    "    correction = mean_ang - 90.0\n",
    "    reliable = (std_ang < VERTICAL_STD_MAX and ROTATION_MIN_CORRECTION < abs(correction) < ROTATION_MAX_CORRECTION)\n",
    "    return correction, reliable\n",
    "\n",
    "# -----------------------------\n",
    "# APPLY ROTATION\n",
    "# -----------------------------\n",
    "def apply_rotation(image, angle):\n",
    "    h, w = image.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1.0)\n",
    "    return cv2.warpAffine(image, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REPLICATE)\n",
    "\n",
    "# -----------------------------\n",
    "# CLUSTER POSITIONS\n",
    "# -----------------------------\n",
    "def cluster_positions(positions, threshold):\n",
    "    if not positions: return []\n",
    "    positions = sorted(positions)\n",
    "    clusters, current = [], [positions[0]]\n",
    "    for p in positions[1:]:\n",
    "        if p - current[-1] <= threshold:\n",
    "            current.append(p)\n",
    "        else:\n",
    "            clusters.append(int(np.mean(current)))\n",
    "            current = [p]\n",
    "    clusters.append(int(np.mean(current)))\n",
    "    return clusters\n",
    "\n",
    "# -----------------------------\n",
    "# SELECT BEST 10 UNIFORMLY SPACED LINES (avoid margins)\n",
    "# -----------------------------\n",
    "def select_best_uniform_10(sorted_positions):\n",
    "    # Requires >=10 positions\n",
    "    if len(sorted_positions) < GRID_EXPECTED_LINES:\n",
    "        return None\n",
    "    best = None\n",
    "    best_score = 1e9\n",
    "    for i in range(len(sorted_positions) - GRID_EXPECTED_LINES + 1):\n",
    "        window = sorted_positions[i:i+GRID_EXPECTED_LINES]\n",
    "        diffs = np.diff(window)\n",
    "        if len(diffs) == 0: continue\n",
    "        max_d = np.max(diffs); min_d = np.min(diffs)\n",
    "        if min_d == 0: continue\n",
    "        ratio = max_d / min_d\n",
    "        # Score: combination of ratio and std for stability\n",
    "        std = np.std(diffs)\n",
    "        score = ratio * (1 + std / (np.mean(diffs)+1e-6))\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best = window\n",
    "    # Sanity: if chosen ratio still poor, return None\n",
    "    if best is not None:\n",
    "        diffs = np.diff(best)\n",
    "        max_d = np.max(diffs); min_d = np.min(diffs)\n",
    "        if min_d == 0 or (max_d / min_d) > UNIFORMITY_RATIO_LIMIT:\n",
    "            return None\n",
    "    return best\n",
    "\n",
    "# -----------------------------\n",
    "# COMPLETE LINES TO EXACT 10\n",
    "# -----------------------------\n",
    "def complete_lines(line_positions, image_extent):\n",
    "    unique = sorted(set(line_positions))\n",
    "    if len(unique) == GRID_EXPECTED_LINES: return unique\n",
    "    if len(unique) < 2:\n",
    "        return [int(round(i * image_extent / (GRID_EXPECTED_LINES - 1))) for i in range(GRID_EXPECTED_LINES)]\n",
    "    first, last = unique[0], unique[-1]\n",
    "    span = last - first\n",
    "    if span < image_extent * 0.5:\n",
    "        first, last = 0, image_extent - 1\n",
    "        span = last - first\n",
    "    step = span / (GRID_EXPECTED_LINES - 1)\n",
    "    return [int(round(first + i * step)) for i in range(GRID_EXPECTED_LINES)]\n",
    "\n",
    "# -----------------------------\n",
    "# SPACING VALIDATION\n",
    "# -----------------------------\n",
    "def spacing_uniform(line_positions):\n",
    "    diffs = np.diff(sorted(line_positions))\n",
    "    if len(diffs) == 0: return False\n",
    "    max_d, min_d = np.max(diffs), np.min(diffs)\n",
    "    if min_d == 0: return False\n",
    "    return (max_d / min_d) < 2.5\n",
    "\n",
    "# -----------------------------\n",
    "# Fallbacks: contour & bounding box\n",
    "# -----------------------------\n",
    "def contour_outer_corners(thresh):\n",
    "    cnts = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "    for c in cnts:\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "        if len(approx) == 4:\n",
    "            return approx.reshape(4,2).astype(np.float32)\n",
    "    return None\n",
    "\n",
    "\n",
    "def bounding_box_corners(mask):\n",
    "    ys, xs = np.where(mask > 0)\n",
    "    if len(xs) == 0 or len(ys) == 0: return None\n",
    "    left, right = int(xs.min()), int(xs.max())\n",
    "    top, bottom = int(ys.min()), int(ys.max())\n",
    "    return np.array([[left, top],[right, top],[right, bottom],[left, bottom]], dtype=np.float32)\n",
    "\n",
    "# -----------------------------\n",
    "# DERIVE CORNERS FROM COMPLETED LINES\n",
    "# -----------------------------\n",
    "def derive_corners(h_lines, v_lines):\n",
    "    return np.array([[v_lines[0], h_lines[0]],[v_lines[-1], h_lines[0]],[v_lines[-1], h_lines[-1]],[v_lines[0], h_lines[-1]]], dtype=np.float32)\n",
    "\n",
    "# -----------------------------\n",
    "# ORDER POINTS & WARP TO SQUARE\n",
    "# -----------------------------\n",
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype=\"float32\")\n",
    "    s = pts.sum(axis=1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    return rect\n",
    "\n",
    "\n",
    "def warp_to_square(image, corners, size=TARGET_SIZE):\n",
    "    rect = order_points(corners)\n",
    "    dst = np.array([[0,0],[size-1,0],[size-1,size-1],[0,size-1]], dtype=np.float32)\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (size, size))\n",
    "    return warped, M\n",
    "\n",
    "# -----------------------------\n",
    "# ENHANCE WARPED IMAGE\n",
    "# -----------------------------\n",
    "def enhance_warped(warped_gray):\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    eq = clahe.apply(warped_gray)\n",
    "    edges = cv2.Canny(eq, 40, 120)\n",
    "    edges = cv2.dilate(edges, np.ones((2,2), np.uint8), iterations=1)\n",
    "    reinforced = cv2.addWeighted(eq, 1.0, edges, 0.15, 0)\n",
    "    blur = cv2.GaussianBlur(reinforced, (3,3), 0)\n",
    "    sharpened = cv2.addWeighted(reinforced, 1.25, blur, -0.25, 0)\n",
    "    return sharpened\n",
    "\n",
    "# -----------------------------\n",
    "# EXTRACT CORNERS FROM PREVIOUS CORNERS IMAGE (RED CIRCLES)\n",
    "# -----------------------------\n",
    "def extract_corners_from_previous(stem):\n",
    "    corners_img_path = os.path.join(PREVIOUS_OUTPUT_DIR, f\"{stem}_corners.jpg\")\n",
    "    if not os.path.exists(corners_img_path): return None\n",
    "    img = cv2.imread(corners_img_path)\n",
    "    if img is None: return None\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    lower1 = np.array([0, 70, 50]); upper1 = np.array([10, 255, 255])\n",
    "    lower2 = np.array([160, 70, 50]); upper2 = np.array([180, 255, 255])\n",
    "    mask = cv2.bitwise_or(cv2.inRange(hsv, lower1, upper1), cv2.inRange(hsv, lower2, upper2))\n",
    "    mask = cv2.medianBlur(mask, 5)\n",
    "    cnts = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "    centers = []\n",
    "    for c in cnts:\n",
    "        area = cv2.contourArea(c)\n",
    "        if 150 < area < 1500:\n",
    "            M = cv2.moments(c)\n",
    "            if M['m00'] > 0:\n",
    "                centers.append([int(M['m10']/M['m00']), int(M['m01']/M['m00'])])\n",
    "    if len(centers) != 4: return None\n",
    "    return np.array(centers, dtype=np.float32)\n",
    "\n",
    "# -----------------------------\n",
    "# PARSE HOUGH OVERLAY (GREEN LINES)\n",
    "# -----------------------------\n",
    "def extract_lines_from_hough_overlay(stem):\n",
    "    path = os.path.join(PREVIOUS_OUTPUT_DIR, f\"{stem}_hough_lines.jpg\")\n",
    "    if not os.path.exists(path): return None\n",
    "    img = cv2.imread(path)\n",
    "    if img is None: return None\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    lower = np.array([35, 60, 40]); upper = np.array([85, 255, 255])\n",
    "    mask = cv2.inRange(hsv, lower, upper)\n",
    "    mask = cv2.dilate(mask, np.ones((3,3), np.uint8), iterations=1)\n",
    "    lines = cv2.HoughLinesP(mask, 1, np.pi/180, 60, minLineLength=40, maxLineGap=15)\n",
    "    return lines\n",
    "\n",
    "# -----------------------------\n",
    "# HOUGH OVERLAY CORNERS (with LS outer fits)\n",
    "# -----------------------------\n",
    "def corners_from_hough_overlay(lines, img_shape):\n",
    "    if lines is None or len(lines) < 4: return None\n",
    "    h_pos = []; v_pos = []; h_segments = []; v_segments = []\n",
    "    for seg in lines:\n",
    "        x1,y1,x2,y2 = seg[0]; dx, dy = x2 - x1, y2 - y1\n",
    "        ang = abs(np.degrees(np.arctan2(dy, dx)))\n",
    "        if ang < 12 or ang > 168:\n",
    "            h_pos.append((y1+y2)/2.0); h_segments.append([(x1,y1),(x2,y2)])\n",
    "        elif 78 < ang < 102:\n",
    "            v_pos.append((x1+x2)/2.0); v_segments.append([(x1,y1),(x2,y2)])\n",
    "    if len(h_pos) < 2 or len(v_pos) < 2: return None\n",
    "    h_thresh = max(10, img_shape[0]//80); v_thresh = max(10, img_shape[1]//80)\n",
    "    h_clusters = cluster_positions(h_pos, h_thresh)\n",
    "    v_clusters = cluster_positions(v_pos, v_thresh)\n",
    "    # Inner selection if many clusters\n",
    "    if len(h_clusters) > GRID_EXPECTED_LINES:\n",
    "        sel = select_best_uniform_10(h_clusters)\n",
    "        if sel is not None: h_clusters = sel\n",
    "    if len(v_clusters) > GRID_EXPECTED_LINES:\n",
    "        sel = select_best_uniform_10(v_clusters)\n",
    "        if sel is not None: v_clusters = sel\n",
    "    if len(h_clusters) < 2 or len(v_clusters) < 2: return None\n",
    "    top_y, bottom_y = h_clusters[0], h_clusters[-1]\n",
    "    left_x, right_x = v_clusters[0], v_clusters[-1]\n",
    "    def collect(seg_list, target, axis='y', tol=15):\n",
    "        pts = []\n",
    "        for seg in seg_list:\n",
    "            for (x,y) in seg:\n",
    "                val = y if axis=='y' else x\n",
    "                if abs(val - target) <= tol: pts.append((x,y))\n",
    "        return pts\n",
    "    top_pts = collect(h_segments, top_y, 'y'); bottom_pts = collect(h_segments, bottom_y, 'y')\n",
    "    left_pts = collect(v_segments, left_x, 'x'); right_pts = collect(v_segments, right_x, 'x')\n",
    "    def fit_line(points, mode='horizontal'):\n",
    "        if len(points) < 2: return None\n",
    "        pts = np.array(points, dtype=np.float32); x = pts[:,0]; y = pts[:,1]\n",
    "        if mode=='horizontal':\n",
    "            A = np.vstack([x, np.ones_like(x)]).T; m, b = np.linalg.lstsq(A, y, rcond=None)[0]; return ('h', m, b)\n",
    "        else:\n",
    "            A = np.vstack([y, np.ones_like(y)]).T; m, b = np.linalg.lstsq(A, x, rcond=None)[0]; return ('v', m, b)\n",
    "    top_line = fit_line(top_pts, 'horizontal'); bottom_line = fit_line(bottom_pts, 'horizontal')\n",
    "    left_line = fit_line(left_pts, 'vertical'); right_line = fit_line(right_pts, 'vertical')\n",
    "    if None in (top_line,bottom_line,left_line,right_line): return None\n",
    "    def line_to_abc(line):\n",
    "        kind,m,b = line\n",
    "        if kind=='h': return m, -1.0, b\n",
    "        return 1.0, -m, -b\n",
    "    def intersect(l1,l2):\n",
    "        a1,b1,c1 = line_to_abc(l1); a2,b2,c2 = line_to_abc(l2); det = a1*b2 - a2*b1\n",
    "        if abs(det)<1e-8: return None\n",
    "        x = (-c1*b2 + c2*b1)/det; y = (-a1*c2 + a2*c1)/det\n",
    "        return np.array([x,y], dtype=np.float32)\n",
    "    tl = intersect(top_line,left_line); tr = intersect(top_line,right_line)\n",
    "    br = intersect(bottom_line,right_line); bl = intersect(bottom_line,left_line)\n",
    "    if None in (tl,tr,br,bl): return None\n",
    "    corners = np.array([tl,tr,br,bl], dtype=np.float32)\n",
    "    xs = corners[:,0]; ys = corners[:,1]\n",
    "    if not (0 <= xs.min() < img_shape[1] and 0 <= xs.max() <= img_shape[1] and 0 <= ys.min() < img_shape[0] and 0 <= ys.max() <= img_shape[0]):\n",
    "        return None\n",
    "    return corners\n",
    "\n",
    "# -----------------------------\n",
    "# MAIN REFINEMENT (INCLUDES INNER SELECTION)\n",
    "# -----------------------------\n",
    "def refine_sudoku_image(input_path, output_dir):\n",
    "    base_name = os.path.basename(input_path); stem = os.path.splitext(base_name)[0]\n",
    "    img = cv2.imread(input_path)\n",
    "    if img is None:\n",
    "        print(f\"[FAIL] Cannot read {input_path}\"); return False\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    reuse_success = False; hough_success = False\n",
    "    # 1. Reuse corners (red circles)\n",
    "    reused_corners = extract_corners_from_previous(stem)\n",
    "    if reused_corners is not None:\n",
    "        xs = reused_corners[:,0]; ys = reused_corners[:,1]\n",
    "        w_span = xs.max()-xs.min(); h_span = ys.max()-ys.min()\n",
    "        area_ratio = (w_span*h_span)/(gray.shape[0]*gray.shape[1]); aspect = w_span/max(1,h_span)\n",
    "        if area_ratio > 0.25 and 0.6 < aspect < 1.6:\n",
    "            corners = reused_corners; reuse_success = True\n",
    "            print(f\"[REUSE] {base_name}: accepted (areaRatio={area_ratio:.2f}, aspect={aspect:.2f})\")\n",
    "        else:\n",
    "            print(f\"[REUSE-REJECT] {base_name}: sanity failed\")\n",
    "    # 2. Hough overlay parse\n",
    "    if not reuse_success:\n",
    "        hough_lines = extract_lines_from_hough_overlay(stem)\n",
    "        if hough_lines is not None:\n",
    "            overlay_corners = corners_from_hough_overlay(hough_lines, gray.shape)\n",
    "            if overlay_corners is not None:\n",
    "                xs = overlay_corners[:,0]; ys = overlay_corners[:,1]\n",
    "                w_span = xs.max()-xs.min(); h_span = ys.max()-ys.min()\n",
    "                area_ratio = (w_span*h_span)/(gray.shape[0]*gray.shape[1]); aspect = w_span/max(1,h_span)\n",
    "                if area_ratio > 0.25 and 0.6 < aspect < 1.6:\n",
    "                    corners = overlay_corners; hough_success = True\n",
    "                    print(f\"[HOUGH-OVERLAY] {base_name}: accepted (areaRatio={area_ratio:.2f}, aspect={aspect:.2f})\")\n",
    "                else:\n",
    "                    print(f\"[HOUGH-REJECT] {base_name}: sanity failed\")\n",
    "            else:\n",
    "                print(f\"[HOUGH-NO-CORNERS] {base_name}\")\n",
    "        else:\n",
    "            print(f\"[HOUGH-NO-LINES] {base_name}\")\n",
    "    # 3. Fallback detection path\n",
    "    if not (reuse_success or hough_success):\n",
    "        lines_pass1, grid_mask1, thresh1 = detect_grid_lines(gray)\n",
    "        h_pos1, v_pos1, v_angles1 = classify_lines(lines_pass1)\n",
    "        correction, reliable = estimate_rotation(v_angles1)\n",
    "        if reliable:\n",
    "            img = apply_rotation(img, -correction); gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            print(f\"[ROTATE] {base_name}: {-correction:.2f}° applied\")\n",
    "            lines, grid_mask, thresh = detect_grid_lines(gray)\n",
    "        else:\n",
    "            lines, grid_mask, thresh = lines_pass1, grid_mask1, thresh1\n",
    "            print(f\"[NO-ROTATE] {base_name}: correction={correction:.2f} reliable={reliable} count={len(v_angles1)}\")\n",
    "        horiz, vert, _ = classify_lines(lines)\n",
    "        h_thresh = max(10, gray.shape[0]//80); v_thresh = max(10, gray.shape[1]//80)\n",
    "        h_clusters = cluster_positions(horiz, h_thresh); v_clusters = cluster_positions(vert, v_thresh)\n",
    "        # Inner selection before completion\n",
    "        if len(h_clusters) > GRID_EXPECTED_LINES:\n",
    "            sel = select_best_uniform_10(h_clusters)\n",
    "            if sel is not None: h_clusters = sel\n",
    "        if len(v_clusters) > GRID_EXPECTED_LINES:\n",
    "            sel = select_best_uniform_10(v_clusters)\n",
    "            if sel is not None: v_clusters = sel\n",
    "        h_completed = h_clusters if len(h_clusters)==GRID_EXPECTED_LINES else complete_lines(h_clusters, gray.shape[0])\n",
    "        v_completed = v_clusters if len(v_clusters)==GRID_EXPECTED_LINES else complete_lines(v_clusters, gray.shape[1])\n",
    "        spacing_ok = spacing_uniform(h_completed) and spacing_uniform(v_completed)\n",
    "        corners = derive_corners(h_completed, v_completed)\n",
    "        area_lines = (max(v_completed)-min(v_completed))*(max(h_completed)-min(h_completed))\n",
    "        full_area = gray.shape[0]*gray.shape[1]; area_ratio = area_lines/full_area\n",
    "        aspect = (max(v_completed)-min(v_completed))/max(1,(max(h_completed)-min(h_completed)))\n",
    "        unreliable = (area_ratio < 0.35) or (aspect < 0.75 or aspect > 1.35) or (not spacing_ok)\n",
    "        if unreliable:\n",
    "            contour_c = contour_outer_corners(thresh)\n",
    "            if contour_c is not None:\n",
    "                corners = contour_c; print(f\"[FALLBACK-CONTOUR] {base_name}\")\n",
    "            else:\n",
    "                bbox_c = bounding_box_corners(grid_mask)\n",
    "                if bbox_c is not None:\n",
    "                    corners = bbox_c; print(f\"[FALLBACK-BOX] {base_name}\")\n",
    "                else:\n",
    "                    print(f\"[FAIL] {base_name}: no reliable corners\"); return False\n",
    "        else:\n",
    "            print(f\"[LINES] {base_name}: accepted (areaRatio={area_ratio:.2f}, aspect={aspect:.2f}, spacing_ok={spacing_ok})\")\n",
    "    # Warp\n",
    "    warped_color, M = warp_to_square(img, corners, size=TARGET_SIZE)\n",
    "    warped_gray = cv2.cvtColor(warped_color, cv2.COLOR_BGR2GRAY)\n",
    "    enhanced = enhance_warped(warped_gray)\n",
    "    # Visualization\n",
    "    grid_vis = img.copy()\n",
    "    if 'h_completed' in locals() and not (reuse_success or hough_success):\n",
    "        for y in h_completed: cv2.line(grid_vis, (0,y), (grid_vis.shape[1]-1,y), (0,255,0), 2)\n",
    "        for x in v_completed: cv2.line(grid_vis, (x,0), (grid_vis.shape[0]-1,x), (255,0,0), 2)\n",
    "    for c in corners: cv2.circle(grid_vis, tuple(c.astype(int)), 10, (0,0,255), -1)\n",
    "    cv2.imwrite(os.path.join(output_dir, f\"{stem}_square_gray.jpg\"), warped_gray)\n",
    "    print(f\"[OK] {base_name}: reuse={reuse_success} hough_used={hough_success} warped={warped_color.shape[:2]}\")\n",
    "    return True\n",
    "\n",
    "# -----------------------------\n",
    "# BATCH REFINEMENT\n",
    "# -----------------------------\n",
    "def refine_batch(input_dir, output_dir):\n",
    "    paths = [p for p in Path(input_dir).glob('*.jpg')]\n",
    "    success = fail = 0\n",
    "    for p in paths:\n",
    "        if refine_sudoku_image(str(p), output_dir): success += 1\n",
    "        else: fail += 1\n",
    "    print(f\"\\nBatch refinement complete: success={success}, failed={fail}, total={len(paths)}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    refine_batch(REFINE_INPUT_DIR, REFINE_OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Consolidated Grid - Draw Black Lines on Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Step 4: Consolidated Grid - Draw Black Lines on Original\n",
      "======================================================================\n",
      "Processing 17 images for consolidated grid...\n",
      "======================================================================\n",
      "\n",
      "[1/17] Processing: 01_square_gray.jpg\n",
      "  → Detecting and drawing grid lines...\n",
      "     Drew 61 line segments\n",
      "  ✓ Saved: /content/drive/MyDrive/Computer Vision Final/consolidated_grid/01_square_gray_consolidated.jpg\n",
      "\n",
      "[2/17] Processing: 02_square_gray.jpg\n",
      "  → Detecting and drawing grid lines...\n",
      "     Drew 62 line segments\n",
      "  ✓ Saved: /content/drive/MyDrive/Computer Vision Final/consolidated_grid/02_square_gray_consolidated.jpg\n",
      "\n",
      "[3/17] Processing: 03_square_gray.jpg\n",
      "  → Detecting and drawing grid lines...\n",
      "     Drew 58 line segments\n",
      "  ✓ Saved: /content/drive/MyDrive/Computer Vision Final/consolidated_grid/03_square_gray_consolidated.jpg\n",
      "\n",
      "[4/17] Processing: 04_square_gray.jpg\n",
      "  → Detecting and drawing grid lines...\n",
      "     Drew 41 line segments\n",
      "  ✓ Saved: /content/drive/MyDrive/Computer Vision Final/consolidated_grid/04_square_gray_consolidated.jpg\n",
      "\n",
      "[5/17] Processing: 05_square_gray.jpg\n",
      "  → Detecting and drawing grid lines...\n",
      "     Drew 52 line segments\n",
      "  ✓ Saved: /content/drive/MyDrive/Computer Vision Final/consolidated_grid/05_square_gray_consolidated.jpg\n",
      "\n",
      "[6/17] Processing: 06_square_gray.jpg\n",
      "  → Detecting and drawing grid lines...\n",
      "     Drew 53 line segments\n",
      "  ✓ Saved: /content/drive/MyDrive/Computer Vision Final/consolidated_grid/06_square_gray_consolidated.jpg\n",
      "\n",
      "[7/17] Processing: 07_square_gray.jpg\n",
      "  → Detecting and drawing grid lines...\n",
      "     Drew 61 line segments\n",
      "  ✓ Saved: /content/drive/MyDrive/Computer Vision Final/consolidated_grid/07_square_gray_consolidated.jpg\n",
      "\n",
      "[8/17] Processing: 08_square_gray.jpg\n",
      "  → Detecting and drawing grid lines...\n",
      "     Drew 36 line segments\n",
      "  ✓ Saved: /content/drive/MyDrive/Computer Vision Final/consolidated_grid/08_square_gray_consolidated.jpg\n",
      "\n",
      "[9/17] Processing: 09_square_gray.jpg\n",
      "  → Detecting and drawing grid lines...\n",
      "     Drew 63 line segments\n",
      "  ✓ Saved: /content/drive/MyDrive/Computer Vision Final/consolidated_grid/09_square_gray_consolidated.jpg\n",
      "\n",
      "[10/17] Processing: 10_square_gray.jpg\n",
      "  → Detecting and drawing grid lines...\n",
      "     Drew 33 line segments\n",
      "  ✓ Saved: /content/drive/MyDrive/Computer Vision Final/consolidated_grid/10_square_gray_consolidated.jpg\n",
      "\n",
      "[11/17] Processing: 11_square_gray.jpg\n",
      "  → Detecting and drawing grid lines...\n",
      "     Drew 31 line segments\n",
      "  ✓ Saved: /content/drive/MyDrive/Computer Vision Final/consolidated_grid/11_square_gray_consolidated.jpg\n",
      "\n",
      "[12/17] Processing: 12_square_gray.jpg\n",
      "  → Detecting and drawing grid lines...\n",
      "     Drew 71 line segments\n",
      "  ✓ Saved: /content/drive/MyDrive/Computer Vision Final/consolidated_grid/12_square_gray_consolidated.jpg\n",
      "\n",
      "[13/17] Processing: 13_square_gray.jpg\n",
      "  → Detecting and drawing grid lines...\n",
      "     Drew 43 line segments\n",
      "  ✓ Saved: /content/drive/MyDrive/Computer Vision Final/consolidated_grid/13_square_gray_consolidated.jpg\n",
      "\n",
      "[14/17] Processing: 14_square_gray.jpg\n",
      "  → Detecting and drawing grid lines...\n",
      "     Drew 67 line segments\n",
      "  ✓ Saved: /content/drive/MyDrive/Computer Vision Final/consolidated_grid/14_square_gray_consolidated.jpg\n",
      "\n",
      "[15/17] Processing: 15 copy_square_gray.jpg\n",
      "  → Detecting and drawing grid lines...\n",
      "     Drew 3 line segments\n",
      "  ✓ Saved: /content/drive/MyDrive/Computer Vision Final/consolidated_grid/15 copy_square_gray_consolidated.jpg\n",
      "\n",
      "[16/17] Processing: 15_square_gray.jpg\n",
      "  → Detecting and drawing grid lines...\n",
      "     Drew 53 line segments\n",
      "  ✓ Saved: /content/drive/MyDrive/Computer Vision Final/consolidated_grid/15_square_gray_consolidated.jpg\n",
      "\n",
      "[17/17] Processing: 16_square_gray.jpg\n",
      "  → Detecting and drawing grid lines...\n",
      "     Drew 18 line segments\n",
      "  ✓ Saved: /content/drive/MyDrive/Computer Vision Final/consolidated_grid/16_square_gray_consolidated.jpg\n",
      "\n",
      "======================================================================\n",
      "✓ Consolidated grid processing complete!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuration\n",
    "INPUT_DIR = '/content/drive/MyDrive/Computer Vision Final/final_square'\n",
    "OUTPUT_DIR = '/content/drive/MyDrive/Computer Vision Final/consolidated_grid'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# LINE DETECTION (SAME AS STEP 2)\n",
    "# -----------------------------\n",
    "def detect_and_draw_grid_lines(image):\n",
    "    \"\"\"\n",
    "    Apply line detection as in Step 2 and draw black lines on original image\n",
    "    \"\"\"\n",
    "    # Convert to grayscale\n",
    "    if len(image.shape) == 3:\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = image.copy()\n",
    "\n",
    "    # Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Adaptive threshold - inverted (lines are white on black)\n",
    "    thresh = cv2.adaptiveThreshold(\n",
    "        blurred, 255,\n",
    "        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "        cv2.THRESH_BINARY_INV,\n",
    "        11, 2\n",
    "    )\n",
    "\n",
    "    # Extract horizontal lines\n",
    "    horizontal = thresh.copy()\n",
    "    h_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (40, 1))\n",
    "    horizontal = cv2.erode(horizontal, h_kernel, iterations=1)\n",
    "    horizontal = cv2.dilate(horizontal, h_kernel, iterations=1)\n",
    "\n",
    "    # Extract vertical lines\n",
    "    vertical = thresh.copy()\n",
    "    v_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 40))\n",
    "    vertical = cv2.erode(vertical, v_kernel, iterations=1)\n",
    "    vertical = cv2.dilate(vertical, v_kernel, iterations=1)\n",
    "\n",
    "    # Combine them to get grid mask\n",
    "    grid_mask = cv2.addWeighted(horizontal, 0.5, vertical, 0.5, 0)\n",
    "\n",
    "    # Hough Line Transform\n",
    "    lines = cv2.HoughLinesP(\n",
    "        grid_mask,\n",
    "        rho=1,\n",
    "        theta=np.pi/180,\n",
    "        threshold=150,\n",
    "        minLineLength=100,\n",
    "        maxLineGap=10\n",
    "    )\n",
    "\n",
    "    # Draw black lines on original image\n",
    "    result = image.copy()\n",
    "    if len(result.shape) == 2:\n",
    "        result = cv2.cvtColor(result, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    line_count = 0\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]\n",
    "            cv2.line(result, (x1, y1), (x2, y2), (0, 0, 0), 2)  # Black lines\n",
    "            line_count += 1\n",
    "\n",
    "    return result, line_count\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# BATCH PROCESSING\n",
    "# -----------------------------\n",
    "def process_consolidated_grid(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Process all images: detect lines and draw black lines on original\n",
    "    \"\"\"\n",
    "    input_files = sorted([f for f in os.listdir(input_dir) if f.endswith('.jpg')])\n",
    "\n",
    "    if not input_files:\n",
    "        print(f\"No images found in {input_dir}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Processing {len(input_files)} images for consolidated grid...\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for idx, filename in enumerate(input_files, 1):\n",
    "        print(f\"\\n[{idx}/{len(input_files)}] Processing: {filename}\")\n",
    "\n",
    "        # Load image\n",
    "        img_path = os.path.join(input_dir, filename)\n",
    "        image = cv2.imread(img_path)\n",
    "\n",
    "        if image is None:\n",
    "            print(f\"  ❌ Failed to load image\")\n",
    "            continue\n",
    "\n",
    "        # Detect and draw grid lines\n",
    "        print(f\"  → Detecting and drawing grid lines...\")\n",
    "        result, line_count = detect_and_draw_grid_lines(image)\n",
    "        print(f\"     Drew {line_count} line segments\")\n",
    "\n",
    "        # Save result\n",
    "        base_name = os.path.splitext(filename)[0]\n",
    "        output_path = os.path.join(output_dir, f\"{base_name}_consolidated.jpg\")\n",
    "        cv2.imwrite(output_path, result)\n",
    "\n",
    "        print(f\"  ✓ Saved: {output_path}\")\n",
    "\n",
    "        results[filename] = {\n",
    "            'line_count': line_count,\n",
    "            'output': output_path\n",
    "        }\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"✓ Consolidated grid processing complete!\")\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# EXECUTE PIPELINE\n",
    "# -----------------------------\n",
    "print(\"Starting Step 4: Consolidated Grid - Draw Black Lines on Original\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Process all images\n",
    "results = process_consolidated_grid(INPUT_DIR, OUTPUT_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Complete Grid Lines\n",
    "Read from Step 4 (consolidated_grid) and complete lines to form perfect grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Processed: 01_square_gray_consolidated.jpg\n",
      "✓ Processed: 02_square_gray_consolidated.jpg\n",
      "✓ Processed: 03_square_gray_consolidated.jpg\n",
      "✓ Processed: 04_square_gray_consolidated.jpg\n",
      "✓ Processed: 05_square_gray_consolidated.jpg\n",
      "✓ Processed: 06_square_gray_consolidated.jpg\n",
      "✓ Processed: 07_square_gray_consolidated.jpg\n",
      "✓ Processed: 08_square_gray_consolidated.jpg\n",
      "✓ Processed: 09_square_gray_consolidated.jpg\n",
      "✓ Processed: 10_square_gray_consolidated.jpg\n",
      "✓ Processed: 11_square_gray_consolidated.jpg\n",
      "✓ Processed: 12_square_gray_consolidated.jpg\n",
      "✓ Processed: 13_square_gray_consolidated.jpg\n",
      "✓ Processed: 14_square_gray_consolidated.jpg\n",
      "✓ Processed: 15 copy_square_gray_consolidated.jpg\n",
      "✓ Processed: 15_square_gray_consolidated.jpg\n",
      "✓ Processed: 16_square_gray_consolidated.jpg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Preprocess a Sudoku cell: 1) Black digit on white background. 2) Remove tiny noise and ignore grid lines.\n",
    "# 3. Keep components that are likely digits.\n",
    "\n",
    "def preprocess_sudoku_cell(cell_path, min_area=50, max_area=1000):\n",
    "    cell_img = cv2.imread(cell_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if cell_img is None:\n",
    "        raise ValueError(f\"Cannot read image: {cell_path}\")\n",
    "\n",
    "    # Threshold to make digits white and background black\n",
    "    _, thresh = cv2.threshold(cell_img, 180, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Find connected components\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(thresh, connectivity=8)\n",
    "\n",
    "    cleaned = np.zeros_like(thresh)\n",
    "\n",
    "    # Keep components within reasonable size\n",
    "    for i in range(1, num_labels):\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "        if min_area <= area <= max_area:\n",
    "            cleaned[labels == i] = 255\n",
    "\n",
    "    # Smooth / fill holes\n",
    "    kernel = np.ones((2,2), np.uint8)\n",
    "    cleaned = cv2.dilate(cleaned, kernel, iterations=1)\n",
    "\n",
    "    # Invert back: black digit on white\n",
    "    final_cell = cv2.bitwise_not(cleaned)\n",
    "\n",
    "    return final_cell\n",
    "\n",
    "# Process the images and save outputs in output directory\n",
    "input_dir = '/content/drive/MyDrive/Computer Vision Final/consolidated_grid'\n",
    "output_dir = '/content/drive/MyDrive/Computer Vision Final/sudoku_preprocessed_final'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "image_files = [f for f in os.listdir(input_dir) if f.endswith('_square_gray_consolidated.jpg')]\n",
    "\n",
    "for filename in image_files:\n",
    "    img_path = os.path.join(input_dir, filename)\n",
    "    processed = preprocess_sudoku_cell(img_path)\n",
    "    base = os.path.splitext(filename)[0]\n",
    "    cv2.imwrite(os.path.join(output_dir, f\"{base}_clean.png\"), processed)\n",
    "    print(f\"✓ Processed: {filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5.5: Define Sudoku Solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# ADDED: Sudoku solver (appended to preserve original file)\n",
    "# -----------------------------\n",
    "def find_empty(grid):\n",
    "    for r in range(9):\n",
    "        for c in range(9):\n",
    "            if grid[r][c] == 0:\n",
    "                return r, c\n",
    "    return None\n",
    "\n",
    "def valid(grid, r, c, val):\n",
    "    # row\n",
    "    if val in grid[r]:\n",
    "        return False\n",
    "    # col\n",
    "    for i in range(9):\n",
    "        if grid[i][c] == val:\n",
    "            return False\n",
    "    # box\n",
    "    br = (r//3)*3\n",
    "    bc = (c//3)*3\n",
    "    for i in range(br, br+3):\n",
    "        for j in range(bc, bc+3):\n",
    "            if grid[i][j] == val:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def solve_sudoku(grid):\n",
    "    pos = find_empty(grid)\n",
    "    if not pos:\n",
    "        return True\n",
    "    r,c = pos\n",
    "    for v in range(1,10):\n",
    "        if valid(grid, r, c, v):\n",
    "            grid[r][c] = v\n",
    "            if solve_sudoku(grid):\n",
    "                return True\n",
    "            grid[r][c] = 0\n",
    "    return False\n",
    "\n",
    "def is_puzzle_legal(grid):\n",
    "    \"\"\"\n",
    "    Quick validation: check for conflicts in rows, columns, and 3x3 boxes.\n",
    "    Returns True if no conflicts found (puzzle is legal).\n",
    "    \"\"\"\n",
    "    # Check rows\n",
    "    for r in range(9):\n",
    "        row_vals = [x for x in grid[r] if x != 0]\n",
    "        if len(row_vals) != len(set(row_vals)):\n",
    "            print(f\"  ✗ Illegal puzzle: duplicate {row_vals[0]} in row {r}\")\n",
    "            return False\n",
    "\n",
    "    # Check columns\n",
    "    for c in range(9):\n",
    "        col_vals = [grid[r][c] for r in range(9) if grid[r][c] != 0]\n",
    "        if len(col_vals) != len(set(col_vals)):\n",
    "            print(f\"  ✗ Illegal puzzle: duplicate {col_vals[0]} in column {c}\")\n",
    "            return False\n",
    "\n",
    "    # Check 3x3 boxes\n",
    "    for box_row in range(3):\n",
    "        for box_col in range(3):\n",
    "            box_vals = []\n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    val = grid[box_row*3 + i][box_col*3 + j]\n",
    "                    if val != 0:\n",
    "                        box_vals.append(val)\n",
    "            if len(box_vals) != len(set(box_vals)):\n",
    "                print(f\"  ✗ Illegal puzzle: duplicate {box_vals[0]} in box ({box_row},{box_col})\")\n",
    "                return False\n",
    "\n",
    "    return True\n",
    "\n",
    "def try_solve_grid(sudoku, out_path=None):\n",
    "    \"\"\"\n",
    "    sudoku: 2D Python list (9x9), 0 = empty.\n",
    "    out_path: optional path to save JSON; if None, nothing is written.\n",
    "    \"\"\"\n",
    "    # ensure proper shape and ints\n",
    "    grid = [[int(x) for x in row] for row in sudoku]\n",
    "    grid_copy = [row[:] for row in grid]\n",
    "\n",
    "    # ---------- NEW: Legal check before solving ----------\n",
    "    print(\"  → Checking puzzle legality...\")\n",
    "    if not is_puzzle_legal(grid_copy):\n",
    "        print(\"  ✗ Skipping solver: puzzle has conflicts\")\n",
    "        return False, None\n",
    "\n",
    "    num_empty = sum(1 for row in grid_copy for cell in row if cell == 0)\n",
    "    print(f\"  ✓ Puzzle is legal ({81-num_empty}/81 digits filled)\")\n",
    "\n",
    "    solvable = solve_sudoku(grid_copy)\n",
    "    if solvable:\n",
    "        if out_path is not None:\n",
    "            import json, os\n",
    "            os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "            with open(out_path, \"w\") as f:\n",
    "                json.dump(grid_copy, f, indent=2)\n",
    "            print(f\"Solver: solved and wrote to {out_path}\")\n",
    "        else:\n",
    "            print(\"Solver: solved (no output path provided, not saved)\")\n",
    "        return True, grid_copy\n",
    "    else:\n",
    "        print(\"Solver: puzzle not solvable or incomplete detections.\")\n",
    "        return False, None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Draw Clean Sudoku Grid\n",
    "Read from Step 5 output and create a clean 9x9 Sudoku grid visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Loading templates from template_centered_resized directory...\n",
      "======================================================================\n",
      "  ✓ Loaded & preprocessed template 1\n",
      "  ✓ Loaded & preprocessed template 2\n",
      "  ✓ Loaded & preprocessed template 3\n",
      "  ✓ Loaded & preprocessed template 4\n",
      "  ✓ Loaded & preprocessed template 5\n",
      "  ✓ Loaded & preprocessed template 6\n",
      "  ✓ Loaded & preprocessed template 7\n",
      "  ✓ Loaded & preprocessed template 8\n",
      "  ✓ Loaded & preprocessed template 9\n",
      "\n",
      "✓ Successfully loaded 9 templates\n",
      "======================================================================\n",
      "======================================================================\n",
      "SUDOKU OCR WITH CELL EXTRACTION\n",
      "======================================================================\n",
      "Input: /content/drive/MyDrive/Computer Vision Final/sudoku_preprocessed_final\n",
      "Output: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results\n",
      "Found 17 images to process\n",
      "======================================================================\n",
      "\n",
      "[Image 1] 01_square_gray_consolidated_clean\n",
      "  → Saved 81 cells to: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_01_01_square_gray_consolidated_clean/cells\n",
      "  → Recognizing digits using CV algorithms...\n",
      "  → Detected 26 digits\n",
      "  → Sudoku Grid:\n",
      "     8 . . . . . . 4 .\n",
      "     . . 3 6 . . . . .\n",
      "     . 7 . . 9 . 2 . 3\n",
      "     . 5 . . . 7 . . .\n",
      "     . . . . 4 8 7 . .\n",
      "     2 . . 1 . . . 3 .\n",
      "     5 . 1 . . . . 6 8\n",
      "     . . 8 5 . . . 1 .\n",
      "     . 9 . . . 8 4 . .\n",
      "  ✓ Saved array: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_01_01_square_gray_consolidated_clean/sudoku_array.txt\n",
      "  ✓ Saved grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_01_01_square_gray_consolidated_clean/sudoku_grid.jpg\n",
      "  ✓ Saved empty grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_01_01_square_gray_consolidated_clean/empty_grid.jpg\n",
      "  → Solving detected Sudoku...\n",
      "  → Checking puzzle legality...\n",
      "  ✗ Illegal puzzle: duplicate 7 in column 5\n",
      "  ✗ Skipping solver: puzzle has conflicts\n",
      "  ✗ Sudoku could not be solved\n",
      "\n",
      "[Image 2] 02_square_gray_consolidated_clean\n",
      "  → Saved 81 cells to: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_02_02_square_gray_consolidated_clean/cells\n",
      "  → Recognizing digits using CV algorithms...\n",
      "  → Detected 29 digits\n",
      "  → Sudoku Grid:\n",
      "     . 8 . 1 6 6 . . .\n",
      "     . 8 . . 2 . . 7 .\n",
      "     6 . . . . . 6 . .\n",
      "     . 1 . 6 . . 9 . .\n",
      "     2 . . 9 4 1 . . 6\n",
      "     . . 8 . . 6 . 7 .\n",
      "     . . 7 . . . . . 9\n",
      "     . 5 . . 1 . . 8 .\n",
      "     . . . 2 6 8 . 4 .\n",
      "  ✓ Saved array: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_02_02_square_gray_consolidated_clean/sudoku_array.txt\n",
      "  ✓ Saved grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_02_02_square_gray_consolidated_clean/sudoku_grid.jpg\n",
      "  ✓ Saved empty grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_02_02_square_gray_consolidated_clean/empty_grid.jpg\n",
      "  → Solving detected Sudoku...\n",
      "  → Checking puzzle legality...\n",
      "  ✗ Illegal puzzle: duplicate 8 in row 0\n",
      "  ✗ Skipping solver: puzzle has conflicts\n",
      "  ✗ Sudoku could not be solved\n",
      "\n",
      "[Image 3] 03_square_gray_consolidated_clean\n",
      "  → Saved 81 cells to: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_03_03_square_gray_consolidated_clean/cells\n",
      "  → Recognizing digits using CV algorithms...\n",
      "  → Detected 34 digits\n",
      "  → Sudoku Grid:\n",
      "     . 2 . 5 . . 1 . 6\n",
      "     . 1 8 4 . . . . 7\n",
      "     5 7 3 6 . . 9 . .\n",
      "     . 3 1 9 7 . 2 . 5\n",
      "     . . . . 8 6 . . .\n",
      "     . 9 6 . . . 8 1 4\n",
      "     . . . . . . 4 . 9\n",
      "     1 6 . . . 9 . 7 .\n",
      "     . . . 8 . . . . 1\n",
      "  ✓ Saved array: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_03_03_square_gray_consolidated_clean/sudoku_array.txt\n",
      "  ✓ Saved grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_03_03_square_gray_consolidated_clean/sudoku_grid.jpg\n",
      "  ✓ Saved empty grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_03_03_square_gray_consolidated_clean/empty_grid.jpg\n",
      "  → Solving detected Sudoku...\n",
      "  → Checking puzzle legality...\n",
      "  ✓ Puzzle is legal (34/81 digits filled)\n",
      "Solver: solved and wrote to /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_03_03_square_gray_consolidated_clean/sudoku_solved.json\n",
      "  ✓ Sudoku solved during pipeline\n",
      "\n",
      "[Image 4] 04_square_gray_consolidated_clean\n",
      "  → Saved 81 cells to: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_04_04_square_gray_consolidated_clean/cells\n",
      "  → Recognizing digits using CV algorithms...\n",
      "  → Detected 30 digits\n",
      "  → Sudoku Grid:\n",
      "     4 7 . . . . . 9 .\n",
      "     . . . 6 . . . . .\n",
      "     3 . . . 7 . 8 . .\n",
      "     . . . 4 8 . . . 6\n",
      "     . . 7 . . . . . 2\n",
      "     7 9 . . . . 8 8 7\n",
      "     . 4 . . . 2 . . .\n",
      "     9 3 . 7 7 6 5 4 .\n",
      "     . 5 . . 3 4 . 7 .\n",
      "  ✓ Saved array: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_04_04_square_gray_consolidated_clean/sudoku_array.txt\n",
      "  ✓ Saved grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_04_04_square_gray_consolidated_clean/sudoku_grid.jpg\n",
      "  ✓ Saved empty grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_04_04_square_gray_consolidated_clean/empty_grid.jpg\n",
      "  → Solving detected Sudoku...\n",
      "  → Checking puzzle legality...\n",
      "  ✗ Illegal puzzle: duplicate 7 in row 5\n",
      "  ✗ Skipping solver: puzzle has conflicts\n",
      "  ✗ Sudoku could not be solved\n",
      "\n",
      "[Image 5] 05_square_gray_consolidated_clean\n",
      "  → Saved 81 cells to: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_05_05_square_gray_consolidated_clean/cells\n",
      "  → Recognizing digits using CV algorithms...\n",
      "  → Detected 35 digits\n",
      "  → Sudoku Grid:\n",
      "     8 . 6 . . 8 . 8 .\n",
      "     . 4 . . 7 . . 8 8\n",
      "     2 . . 8 7 . . . 5\n",
      "     7 . 8 . . 6 . 2 .\n",
      "     . 3 . 7 . . . 5 .\n",
      "     7 . 5 . 8 . 8 . .\n",
      "     . 2 7 . . 7 . 4 .\n",
      "     6 . . . 2 . 8 . .\n",
      "     . 8 7 8 . 4 . . 2\n",
      "  ✓ Saved array: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_05_05_square_gray_consolidated_clean/sudoku_array.txt\n",
      "  ✓ Saved grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_05_05_square_gray_consolidated_clean/sudoku_grid.jpg\n",
      "  ✓ Saved empty grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_05_05_square_gray_consolidated_clean/empty_grid.jpg\n",
      "  → Solving detected Sudoku...\n",
      "  → Checking puzzle legality...\n",
      "  ✗ Illegal puzzle: duplicate 8 in row 0\n",
      "  ✗ Skipping solver: puzzle has conflicts\n",
      "  ✗ Sudoku could not be solved\n",
      "\n",
      "[Image 6] 06_square_gray_consolidated_clean\n",
      "  → Saved 81 cells to: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_06_06_square_gray_consolidated_clean/cells\n",
      "  → Recognizing digits using CV algorithms...\n",
      "  → Detected 37 digits\n",
      "  → Sudoku Grid:\n",
      "     . . . . . . . . .\n",
      "     7 . 7 8 . 3 . 8 1\n",
      "     . . . . . 1 8 4 .\n",
      "     5 . 4 . . 8 9 . .\n",
      "     . . 9 9 . 8 3 . .\n",
      "     8 4 8 8 9 9 . 8 .\n",
      "     8 8 4 6 8 . 8 7 .\n",
      "     . 5 . . . 7 . . .\n",
      "     . . 6 7 . . . 9 8\n",
      "  ✓ Saved array: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_06_06_square_gray_consolidated_clean/sudoku_array.txt\n",
      "  ✓ Saved grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_06_06_square_gray_consolidated_clean/sudoku_grid.jpg\n",
      "  ✓ Saved empty grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_06_06_square_gray_consolidated_clean/empty_grid.jpg\n",
      "  → Solving detected Sudoku...\n",
      "  → Checking puzzle legality...\n",
      "  ✗ Illegal puzzle: duplicate 7 in row 1\n",
      "  ✗ Skipping solver: puzzle has conflicts\n",
      "  ✗ Sudoku could not be solved\n",
      "\n",
      "[Image 7] 07_square_gray_consolidated_clean\n",
      "  → Saved 81 cells to: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_07_07_square_gray_consolidated_clean/cells\n",
      "  → Recognizing digits using CV algorithms...\n",
      "  → Detected 31 digits\n",
      "  → Sudoku Grid:\n",
      "     2 . . 8 . 8 . . .\n",
      "     8 . 6 8 . . 4 . 8\n",
      "     . . . . . . 6 . 8\n",
      "     4 . 6 . 8 8 . . .\n",
      "     . . . 8 . . 7 . 9\n",
      "     . . 7 . 4 . . 8 .\n",
      "     7 . 6 8 7 . . . .\n",
      "     . 8 . . . . 8 . 4\n",
      "     . . 4 . 7 8 . . 7\n",
      "  ✓ Saved array: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_07_07_square_gray_consolidated_clean/sudoku_array.txt\n",
      "  ✓ Saved grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_07_07_square_gray_consolidated_clean/sudoku_grid.jpg\n",
      "  ✓ Saved empty grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_07_07_square_gray_consolidated_clean/empty_grid.jpg\n",
      "  → Solving detected Sudoku...\n",
      "  → Checking puzzle legality...\n",
      "  ✗ Illegal puzzle: duplicate 2 in row 0\n",
      "  ✗ Skipping solver: puzzle has conflicts\n",
      "  ✗ Sudoku could not be solved\n",
      "\n",
      "[Image 8] 08_square_gray_consolidated_clean\n",
      "  → Saved 81 cells to: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_08_08_square_gray_consolidated_clean/cells\n",
      "  → Recognizing digits using CV algorithms...\n",
      "  → Detected 26 digits\n",
      "  → Sudoku Grid:\n",
      "     4 . . . 3 . 8 . 6\n",
      "     . . . . . 8 . . 1\n",
      "     3 . . 7 . . . . 9\n",
      "     9 . 4 . . . . . .\n",
      "     . . . . 3 . . 1 .\n",
      "     5 . 1 . . 7 . . 3\n",
      "     . 1 . 8 . . . . .\n",
      "     . . . . . 7 . . 1\n",
      "     2 . 5 . 1 . 7 . 7\n",
      "  ✓ Saved array: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_08_08_square_gray_consolidated_clean/sudoku_array.txt\n",
      "  ✓ Saved grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_08_08_square_gray_consolidated_clean/sudoku_grid.jpg\n",
      "  ✓ Saved empty grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_08_08_square_gray_consolidated_clean/empty_grid.jpg\n",
      "  → Solving detected Sudoku...\n",
      "  → Checking puzzle legality...\n",
      "  ✗ Illegal puzzle: duplicate 2 in row 8\n",
      "  ✗ Skipping solver: puzzle has conflicts\n",
      "  ✗ Sudoku could not be solved\n",
      "\n",
      "[Image 9] 09_square_gray_consolidated_clean\n",
      "  → Saved 81 cells to: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_09_09_square_gray_consolidated_clean/cells\n",
      "  → Recognizing digits using CV algorithms...\n",
      "  → Detected 28 digits\n",
      "  → Sudoku Grid:\n",
      "     . 2 8 8 . . . 6 .\n",
      "     8 . . . . . 2 . 9\n",
      "     . 1 . . . 2 . . 8\n",
      "     . . 8 . 1 . . . 8\n",
      "     . . . 6 . 9 . . .\n",
      "     6 . . . 8 . 9 . .\n",
      "     2 . . 1 . . . 9 .\n",
      "     9 . 1 . . . . . 6\n",
      "     . 4 . . . 6 3 7 .\n",
      "  ✓ Saved array: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_09_09_square_gray_consolidated_clean/sudoku_array.txt\n",
      "  ✓ Saved grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_09_09_square_gray_consolidated_clean/sudoku_grid.jpg\n",
      "  ✓ Saved empty grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_09_09_square_gray_consolidated_clean/empty_grid.jpg\n",
      "  → Solving detected Sudoku...\n",
      "  → Checking puzzle legality...\n",
      "  ✗ Illegal puzzle: duplicate 2 in row 0\n",
      "  ✗ Skipping solver: puzzle has conflicts\n",
      "  ✗ Sudoku could not be solved\n",
      "\n",
      "[Image 10] 10_square_gray_consolidated_clean\n",
      "  → Saved 81 cells to: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_10_10_square_gray_consolidated_clean/cells\n",
      "  → Recognizing digits using CV algorithms...\n",
      "  → Detected 49 digits\n",
      "  → Sudoku Grid:\n",
      "     . 8 8 4 8 8 . . .\n",
      "     8 8 8 . 8 1 . 4 6\n",
      "     4 . 8 . 7 1 8 4 9\n",
      "     8 8 8 8 8 9 . . 8\n",
      "     . 8 . . 1 . . 9 .\n",
      "     9 . . 6 . 8 . 7 2\n",
      "     8 3 7 9 6 . 8 . 4\n",
      "     6 8 . . 9 . . 8 8\n",
      "     . . . . 8 . 8 8 .\n",
      "  ✓ Saved array: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_10_10_square_gray_consolidated_clean/sudoku_array.txt\n",
      "  ✓ Saved grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_10_10_square_gray_consolidated_clean/sudoku_grid.jpg\n",
      "  ✓ Saved empty grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_10_10_square_gray_consolidated_clean/empty_grid.jpg\n",
      "  → Solving detected Sudoku...\n",
      "  → Checking puzzle legality...\n",
      "  ✗ Illegal puzzle: duplicate 8 in row 0\n",
      "  ✗ Skipping solver: puzzle has conflicts\n",
      "  ✗ Sudoku could not be solved\n",
      "\n",
      "[Image 11] 11_square_gray_consolidated_clean\n",
      "  → Saved 81 cells to: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_11_11_square_gray_consolidated_clean/cells\n",
      "  → Recognizing digits using CV algorithms...\n",
      "  → Detected 27 digits\n",
      "  → Sudoku Grid:\n",
      "     . 1 7 . . . 3 5 .\n",
      "     9 . . 1 . 9 . . 8\n",
      "     3 . . . 7 . . . 2\n",
      "     . . . . 4 . . 8 .\n",
      "     . . 5 6 . 8 4 . .\n",
      "     . . . . 9 . . 1 .\n",
      "     . . . . 6 . . . 4\n",
      "     . . . 4 . 7 . . 6\n",
      "     . . 3 . . . 8 7 .\n",
      "  ✓ Saved array: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_11_11_square_gray_consolidated_clean/sudoku_array.txt\n",
      "  ✓ Saved grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_11_11_square_gray_consolidated_clean/sudoku_grid.jpg\n",
      "  ✓ Saved empty grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_11_11_square_gray_consolidated_clean/empty_grid.jpg\n",
      "  → Solving detected Sudoku...\n",
      "  → Checking puzzle legality...\n",
      "  ✗ Illegal puzzle: duplicate 9 in row 1\n",
      "  ✗ Skipping solver: puzzle has conflicts\n",
      "  ✗ Sudoku could not be solved\n",
      "\n",
      "[Image 12] 12_square_gray_consolidated_clean\n",
      "  → Saved 81 cells to: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_12_12_square_gray_consolidated_clean/cells\n",
      "  → Recognizing digits using CV algorithms...\n",
      "  → Detected 36 digits\n",
      "  → Sudoku Grid:\n",
      "     . . 6 . . . 4 . .\n",
      "     . . . 8 . 4 . . .\n",
      "     . 8 . . 9 . . 4 8\n",
      "     4 . 8 . 9 . 8 . 8\n",
      "     8 . . 4 7 9 . . 8\n",
      "     . 9 9 . . . 4 9 .\n",
      "     8 . . 8 4 8 . . 7\n",
      "     9 . 4 . 4 . 8 . 9\n",
      "     4 8 . . . . . 4 9\n",
      "  ✓ Saved array: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_12_12_square_gray_consolidated_clean/sudoku_array.txt\n",
      "  ✓ Saved grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_12_12_square_gray_consolidated_clean/sudoku_grid.jpg\n",
      "  ✓ Saved empty grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_12_12_square_gray_consolidated_clean/empty_grid.jpg\n",
      "  → Solving detected Sudoku...\n",
      "  → Checking puzzle legality...\n",
      "  ✗ Illegal puzzle: duplicate 8 in row 2\n",
      "  ✗ Skipping solver: puzzle has conflicts\n",
      "  ✗ Sudoku could not be solved\n",
      "\n",
      "[Image 13] 13_square_gray_consolidated_clean\n",
      "  → Saved 81 cells to: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_13_13_square_gray_consolidated_clean/cells\n",
      "  → Recognizing digits using CV algorithms...\n",
      "  → Detected 31 digits\n",
      "  → Sudoku Grid:\n",
      "     . . . 9 . 8 . . .\n",
      "     . 6 . . 8 . . . .\n",
      "     8 . 8 . 9 . 8 . .\n",
      "     . 9 . 8 . 6 . 8 .\n",
      "     . 6 8 . 8 . 8 . .\n",
      "     . 8 . 9 . 6 . 8 .\n",
      "     9 . 4 . 8 . 8 . 8\n",
      "     . 8 . . 6 . . 4 6\n",
      "     . . . 8 . 8 . . .\n",
      "  ✓ Saved array: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_13_13_square_gray_consolidated_clean/sudoku_array.txt\n",
      "  ✓ Saved grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_13_13_square_gray_consolidated_clean/sudoku_grid.jpg\n",
      "  ✓ Saved empty grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_13_13_square_gray_consolidated_clean/empty_grid.jpg\n",
      "  → Solving detected Sudoku...\n",
      "  → Checking puzzle legality...\n",
      "  ✗ Illegal puzzle: duplicate 8 in row 2\n",
      "  ✗ Skipping solver: puzzle has conflicts\n",
      "  ✗ Sudoku could not be solved\n",
      "\n",
      "[Image 14] 14_square_gray_consolidated_clean\n",
      "  → Saved 81 cells to: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_14_14_square_gray_consolidated_clean/cells\n",
      "  → Recognizing digits using CV algorithms...\n",
      "  → Detected 32 digits\n",
      "  → Sudoku Grid:\n",
      "     . . . 8 . . . . 9\n",
      "     . 1 9 . . 5 8 8 .\n",
      "     . 4 8 . 1 . . . 7\n",
      "     4 . . 1 5 . . . 3\n",
      "     . . 2 7 . 4 . 1 .\n",
      "     . 8 . . 9 . 6 . .\n",
      "     . 7 . . . 6 3 . .\n",
      "     . 3 . . 7 . . 8 .\n",
      "     9 . 4 6 . . . . 1\n",
      "  ✓ Saved array: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_14_14_square_gray_consolidated_clean/sudoku_array.txt\n",
      "  ✓ Saved grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_14_14_square_gray_consolidated_clean/sudoku_grid.jpg\n",
      "  ✓ Saved empty grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_14_14_square_gray_consolidated_clean/empty_grid.jpg\n",
      "  → Solving detected Sudoku...\n",
      "  → Checking puzzle legality...\n",
      "  ✗ Illegal puzzle: duplicate 1 in row 1\n",
      "  ✗ Skipping solver: puzzle has conflicts\n",
      "  ✗ Sudoku could not be solved\n",
      "\n",
      "[Image 15] 15 copy_square_gray_consolidated_clean\n",
      "  → Saved 81 cells to: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_15_15 copy_square_gray_consolidated_clean/cells\n",
      "  → Recognizing digits using CV algorithms...\n",
      "  → Detected 37 digits\n",
      "  → Sudoku Grid:\n",
      "     . . . 8 . . 3 4 .\n",
      "     . . . . . 8 4 3 .\n",
      "     . . 4 6 8 9 4 . .\n",
      "     . 8 . . . 6 8 . 8\n",
      "     . 9 8 6 . 4 8 . 3\n",
      "     8 . . 9 8 9 9 6 .\n",
      "     . . 6 9 . 4 4 8 .\n",
      "     7 . . . . 9 . . .\n",
      "     . . . 8 6 4 . . .\n",
      "  ✓ Saved array: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_15_15 copy_square_gray_consolidated_clean/sudoku_array.txt\n",
      "  ✓ Saved grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_15_15 copy_square_gray_consolidated_clean/sudoku_grid.jpg\n",
      "  ✓ Saved empty grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_15_15 copy_square_gray_consolidated_clean/empty_grid.jpg\n",
      "  → Solving detected Sudoku...\n",
      "  → Checking puzzle legality...\n",
      "  ✗ Illegal puzzle: duplicate 4 in row 2\n",
      "  ✗ Skipping solver: puzzle has conflicts\n",
      "  ✗ Sudoku could not be solved\n",
      "\n",
      "[Image 16] 15_square_gray_consolidated_clean\n",
      "  → Saved 81 cells to: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_16_15_square_gray_consolidated_clean/cells\n",
      "  → Recognizing digits using CV algorithms...\n",
      "  → Detected 26 digits\n",
      "  → Sudoku Grid:\n",
      "     . . . . 8 . . . 9\n",
      "     . . . 6 . 1 . 2 .\n",
      "     . . . 5 . 8 . . .\n",
      "     . . 6 1 . 4 8 8 .\n",
      "     . . . . 6 . . . 6\n",
      "     . . 5 9 . 8 4 6 .\n",
      "     . . . 7 . 6 . . .\n",
      "     . . . 8 . 9 . 7 .\n",
      "     . . . . 1 . . . 8\n",
      "  ✓ Saved array: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_16_15_square_gray_consolidated_clean/sudoku_array.txt\n",
      "  ✓ Saved grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_16_15_square_gray_consolidated_clean/sudoku_grid.jpg\n",
      "  ✓ Saved empty grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_16_15_square_gray_consolidated_clean/empty_grid.jpg\n",
      "  → Solving detected Sudoku...\n",
      "  → Checking puzzle legality...\n",
      "  ✗ Illegal puzzle: duplicate 6 in row 3\n",
      "  ✗ Skipping solver: puzzle has conflicts\n",
      "  ✗ Sudoku could not be solved\n",
      "\n",
      "[Image 17] 16_square_gray_consolidated_clean\n",
      "  → Saved 81 cells to: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_17_16_square_gray_consolidated_clean/cells\n",
      "  → Recognizing digits using CV algorithms...\n",
      "  → Detected 29 digits\n",
      "  → Sudoku Grid:\n",
      "     5 . . 7 . . 4 . .\n",
      "     8 . . . 9 . . . .\n",
      "     8 . . . . 1 . . 6\n",
      "     8 . . . . . 7 . 6\n",
      "     8 . 9 . . . 9 4 .\n",
      "     1 6 . . . . . . .\n",
      "     6 . . . 4 . . . .\n",
      "     9 . . 5 . 3 8 . .\n",
      "     4 8 3 . 6 . . 6 6\n",
      "  ✓ Saved array: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_17_16_square_gray_consolidated_clean/sudoku_array.txt\n",
      "  ✓ Saved grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_17_16_square_gray_consolidated_clean/sudoku_grid.jpg\n",
      "  ✓ Saved empty grid: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_17_16_square_gray_consolidated_clean/empty_grid.jpg\n",
      "  → Solving detected Sudoku...\n",
      "  → Checking puzzle legality...\n",
      "  ✗ Illegal puzzle: duplicate 8 in row 4\n",
      "  ✗ Skipping solver: puzzle has conflicts\n",
      "  ✗ Sudoku could not be solved\n",
      "\n",
      "======================================================================\n",
      "✓ PROCESSING COMPLETE\n",
      "  Processed: 17/17 images\n",
      "  Output directory: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results\n",
      "======================================================================\n",
      "\n",
      "SUMMARY OF ALL GRIDS:\n",
      "======================================================================\n",
      "\n",
      "[1] 01_square_gray_consolidated_clean\n",
      "    Digits detected: 26/81\n",
      "    Output: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_01_01_square_gray_consolidated_clean\n",
      "    Cells: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_01_01_square_gray_consolidated_clean/cells\n",
      "    Grid:\n",
      "      8 . . . . . . 4 .\n",
      "      . . 3 6 . . . . .\n",
      "      . 7 . . 9 . 2 . 3\n",
      "      . 5 . . . 7 . . .\n",
      "      . . . . 4 8 7 . .\n",
      "      2 . . 1 . . . 3 .\n",
      "      5 . 1 . . . . 6 8\n",
      "      . . 8 5 . . . 1 .\n",
      "      . 9 . . . 8 4 . .\n",
      "\n",
      "[2] 02_square_gray_consolidated_clean\n",
      "    Digits detected: 29/81\n",
      "    Output: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_02_02_square_gray_consolidated_clean\n",
      "    Cells: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_02_02_square_gray_consolidated_clean/cells\n",
      "    Grid:\n",
      "      . 8 . 1 6 6 . . .\n",
      "      . 8 . . 2 . . 7 .\n",
      "      6 . . . . . 6 . .\n",
      "      . 1 . 6 . . 9 . .\n",
      "      2 . . 9 4 1 . . 6\n",
      "      . . 8 . . 6 . 7 .\n",
      "      . . 7 . . . . . 9\n",
      "      . 5 . . 1 . . 8 .\n",
      "      . . . 2 6 8 . 4 .\n",
      "\n",
      "[3] 03_square_gray_consolidated_clean\n",
      "    Digits detected: 34/81\n",
      "    Output: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_03_03_square_gray_consolidated_clean\n",
      "    Cells: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_03_03_square_gray_consolidated_clean/cells\n",
      "    Grid:\n",
      "      . 2 . 5 . . 1 . 6\n",
      "      . 1 8 4 . . . . 7\n",
      "      5 7 3 6 . . 9 . .\n",
      "      . 3 1 9 7 . 2 . 5\n",
      "      . . . . 8 6 . . .\n",
      "      . 9 6 . . . 8 1 4\n",
      "      . . . . . . 4 . 9\n",
      "      1 6 . . . 9 . 7 .\n",
      "      . . . 8 . . . . 1\n",
      "\n",
      "[4] 04_square_gray_consolidated_clean\n",
      "    Digits detected: 30/81\n",
      "    Output: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_04_04_square_gray_consolidated_clean\n",
      "    Cells: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_04_04_square_gray_consolidated_clean/cells\n",
      "    Grid:\n",
      "      4 7 . . . . . 9 .\n",
      "      . . . 6 . . . . .\n",
      "      3 . . . 7 . 8 . .\n",
      "      . . . 4 8 . . . 6\n",
      "      . . 7 . . . . . 2\n",
      "      7 9 . . . . 8 8 7\n",
      "      . 4 . . . 2 . . .\n",
      "      9 3 . 7 7 6 5 4 .\n",
      "      . 5 . . 3 4 . 7 .\n",
      "\n",
      "[5] 05_square_gray_consolidated_clean\n",
      "    Digits detected: 35/81\n",
      "    Output: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_05_05_square_gray_consolidated_clean\n",
      "    Cells: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_05_05_square_gray_consolidated_clean/cells\n",
      "    Grid:\n",
      "      8 . 6 . . 8 . 8 .\n",
      "      . 4 . . 7 . . 8 8\n",
      "      2 . . 8 7 . . . 5\n",
      "      7 . 8 . . 6 . 2 .\n",
      "      . 3 . 7 . . . 5 .\n",
      "      7 . 5 . 8 . 8 . .\n",
      "      . 2 7 . . 7 . 4 .\n",
      "      6 . . . 2 . 8 . .\n",
      "      . 8 7 8 . 4 . . 2\n",
      "\n",
      "[6] 06_square_gray_consolidated_clean\n",
      "    Digits detected: 37/81\n",
      "    Output: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_06_06_square_gray_consolidated_clean\n",
      "    Cells: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_06_06_square_gray_consolidated_clean/cells\n",
      "    Grid:\n",
      "      . . . . . . . . .\n",
      "      7 . 7 8 . 3 . 8 1\n",
      "      . . . . . 1 8 4 .\n",
      "      5 . 4 . . 8 9 . .\n",
      "      . . 9 9 . 8 3 . .\n",
      "      8 4 8 8 9 9 . 8 .\n",
      "      8 8 4 6 8 . 8 7 .\n",
      "      . 5 . . . 7 . . .\n",
      "      . . 6 7 . . . 9 8\n",
      "\n",
      "[7] 07_square_gray_consolidated_clean\n",
      "    Digits detected: 31/81\n",
      "    Output: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_07_07_square_gray_consolidated_clean\n",
      "    Cells: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_07_07_square_gray_consolidated_clean/cells\n",
      "    Grid:\n",
      "      2 . . 8 . 8 . . .\n",
      "      8 . 6 8 . . 4 . 8\n",
      "      . . . . . . 6 . 8\n",
      "      4 . 6 . 8 8 . . .\n",
      "      . . . 8 . . 7 . 9\n",
      "      . . 7 . 4 . . 8 .\n",
      "      7 . 6 8 7 . . . .\n",
      "      . 8 . . . . 8 . 4\n",
      "      . . 4 . 7 8 . . 7\n",
      "\n",
      "[8] 08_square_gray_consolidated_clean\n",
      "    Digits detected: 26/81\n",
      "    Output: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_08_08_square_gray_consolidated_clean\n",
      "    Cells: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_08_08_square_gray_consolidated_clean/cells\n",
      "    Grid:\n",
      "      4 . . . 3 . 8 . 6\n",
      "      . . . . . 8 . . 1\n",
      "      3 . . 7 . . . . 9\n",
      "      9 . 4 . . . . . .\n",
      "      . . . . 3 . . 1 .\n",
      "      5 . 1 . . 7 . . 3\n",
      "      . 1 . 8 . . . . .\n",
      "      . . . . . 7 . . 1\n",
      "      2 . 5 . 1 . 7 . 7\n",
      "\n",
      "[9] 09_square_gray_consolidated_clean\n",
      "    Digits detected: 28/81\n",
      "    Output: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_09_09_square_gray_consolidated_clean\n",
      "    Cells: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_09_09_square_gray_consolidated_clean/cells\n",
      "    Grid:\n",
      "      . 2 8 8 . . . 6 .\n",
      "      8 . . . . . 2 . 9\n",
      "      . 1 . . . 2 . . 8\n",
      "      . . 8 . 1 . . . 8\n",
      "      . . . 6 . 9 . . .\n",
      "      6 . . . 8 . 9 . .\n",
      "      2 . . 1 . . . 9 .\n",
      "      9 . 1 . . . . . 6\n",
      "      . 4 . . . 6 3 7 .\n",
      "\n",
      "[10] 10_square_gray_consolidated_clean\n",
      "    Digits detected: 49/81\n",
      "    Output: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_10_10_square_gray_consolidated_clean\n",
      "    Cells: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_10_10_square_gray_consolidated_clean/cells\n",
      "    Grid:\n",
      "      . 8 8 4 8 8 . . .\n",
      "      8 8 8 . 8 1 . 4 6\n",
      "      4 . 8 . 7 1 8 4 9\n",
      "      8 8 8 8 8 9 . . 8\n",
      "      . 8 . . 1 . . 9 .\n",
      "      9 . . 6 . 8 . 7 2\n",
      "      8 3 7 9 6 . 8 . 4\n",
      "      6 8 . . 9 . . 8 8\n",
      "      . . . . 8 . 8 8 .\n",
      "\n",
      "[11] 11_square_gray_consolidated_clean\n",
      "    Digits detected: 27/81\n",
      "    Output: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_11_11_square_gray_consolidated_clean\n",
      "    Cells: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_11_11_square_gray_consolidated_clean/cells\n",
      "    Grid:\n",
      "      . 1 7 . . . 3 5 .\n",
      "      9 . . 1 . 9 . . 8\n",
      "      3 . . . 7 . . . 2\n",
      "      . . . . 4 . . 8 .\n",
      "      . . 5 6 . 8 4 . .\n",
      "      . . . . 9 . . 1 .\n",
      "      . . . . 6 . . . 4\n",
      "      . . . 4 . 7 . . 6\n",
      "      . . 3 . . . 8 7 .\n",
      "\n",
      "[12] 12_square_gray_consolidated_clean\n",
      "    Digits detected: 36/81\n",
      "    Output: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_12_12_square_gray_consolidated_clean\n",
      "    Cells: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_12_12_square_gray_consolidated_clean/cells\n",
      "    Grid:\n",
      "      . . 6 . . . 4 . .\n",
      "      . . . 8 . 4 . . .\n",
      "      . 8 . . 9 . . 4 8\n",
      "      4 . 8 . 9 . 8 . 8\n",
      "      8 . . 4 7 9 . . 8\n",
      "      . 9 9 . . . 4 9 .\n",
      "      8 . . 8 4 8 . . 7\n",
      "      9 . 4 . 4 . 8 . 9\n",
      "      4 8 . . . . . 4 9\n",
      "\n",
      "[13] 13_square_gray_consolidated_clean\n",
      "    Digits detected: 31/81\n",
      "    Output: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_13_13_square_gray_consolidated_clean\n",
      "    Cells: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_13_13_square_gray_consolidated_clean/cells\n",
      "    Grid:\n",
      "      . . . 9 . 8 . . .\n",
      "      . 6 . . 8 . . . .\n",
      "      8 . 8 . 9 . 8 . .\n",
      "      . 9 . 8 . 6 . 8 .\n",
      "      . 6 8 . 8 . 8 . .\n",
      "      . 8 . 9 . 6 . 8 .\n",
      "      9 . 4 . 8 . 8 . 8\n",
      "      . 8 . . 6 . . 4 6\n",
      "      . . . 8 . 8 . . .\n",
      "\n",
      "[14] 14_square_gray_consolidated_clean\n",
      "    Digits detected: 32/81\n",
      "    Output: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_14_14_square_gray_consolidated_clean\n",
      "    Cells: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_14_14_square_gray_consolidated_clean/cells\n",
      "    Grid:\n",
      "      . . . 8 . . . . 9\n",
      "      . 1 9 . . 5 8 8 .\n",
      "      . 4 8 . 1 . . . 7\n",
      "      4 . . 1 5 . . . 3\n",
      "      . . 2 7 . 4 . 1 .\n",
      "      . 8 . . 9 . 6 . .\n",
      "      . 7 . . . 6 3 . .\n",
      "      . 3 . . 7 . . 8 .\n",
      "      9 . 4 6 . . . . 1\n",
      "\n",
      "[15] 15 copy_square_gray_consolidated_clean\n",
      "    Digits detected: 37/81\n",
      "    Output: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_15_15 copy_square_gray_consolidated_clean\n",
      "    Cells: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_15_15 copy_square_gray_consolidated_clean/cells\n",
      "    Grid:\n",
      "      . . . 8 . . 3 4 .\n",
      "      . . . . . 8 4 3 .\n",
      "      . . 4 6 8 9 4 . .\n",
      "      . 8 . . . 6 8 . 8\n",
      "      . 9 8 6 . 4 8 . 3\n",
      "      8 . . 9 8 9 9 6 .\n",
      "      . . 6 9 . 4 4 8 .\n",
      "      7 . . . . 9 . . .\n",
      "      . . . 8 6 4 . . .\n",
      "\n",
      "[16] 15_square_gray_consolidated_clean\n",
      "    Digits detected: 26/81\n",
      "    Output: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_16_15_square_gray_consolidated_clean\n",
      "    Cells: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_16_15_square_gray_consolidated_clean/cells\n",
      "    Grid:\n",
      "      . . . . 8 . . . 9\n",
      "      . . . 6 . 1 . 2 .\n",
      "      . . . 5 . 8 . . .\n",
      "      . . 6 1 . 4 8 8 .\n",
      "      . . . . 6 . . . 6\n",
      "      . . 5 9 . 8 4 6 .\n",
      "      . . . 7 . 6 . . .\n",
      "      . . . 8 . 9 . 7 .\n",
      "      . . . . 1 . . . 8\n",
      "\n",
      "[17] 16_square_gray_consolidated_clean\n",
      "    Digits detected: 29/81\n",
      "    Output: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_17_16_square_gray_consolidated_clean\n",
      "    Cells: /content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results/image_17_16_square_gray_consolidated_clean/cells\n",
      "    Grid:\n",
      "      5 . . 7 . . 4 . .\n",
      "      8 . . . 9 . . . .\n",
      "      8 . . . . 1 . . 6\n",
      "      8 . . . . . 7 . 6\n",
      "      8 . 9 . . . 9 4 .\n",
      "      1 6 . . . . . . .\n",
      "      6 . . . 4 . . . .\n",
      "      9 . . 5 . 3 8 . .\n",
      "      4 8 3 . 6 . . 6 6\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Complete Sudoku OCR with Cell Extraction and CV-Based Recognition\n",
    "\n",
    "\n",
    "def load_templates_from_directory(templates_dir):\n",
    "    \"\"\"\n",
    "    Load and preprocess templates with SAME pipeline as cell ROIs:\n",
    "    1. Load template\n",
    "    2. Convert to binary (threshold)\n",
    "    3. Extract main component (ROI)\n",
    "    4. Center the content\n",
    "    5. Resize to standard size\n",
    "    6. Keep as white background (will be inverted during matching)\n",
    "    \"\"\"\n",
    "    templates = {}\n",
    "\n",
    "    for digit in range(1, 10):\n",
    "        template_path = os.path.join(templates_dir, f\"tem_{digit}_centered_resized.png\")\n",
    "\n",
    "        if os.path.exists(template_path):\n",
    "            template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if template is not None:\n",
    "                # Apply SAME preprocessing as cell ROIs\n",
    "                # 1. Threshold to binary (invert to get white digits on black background)\n",
    "                _, binary = cv2.threshold(template, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "                # 2. Clean\n",
    "                kernel = np.ones((2, 2), np.uint8)\n",
    "                cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "                kernel2 = np.ones((3, 3), np.uint8)\n",
    "                cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, kernel2, iterations=1)\n",
    "\n",
    "                # 3. Extract main component\n",
    "                contours, _ = cv2.findContours(cleaned, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                if contours:\n",
    "                    main_contour = max(contours, key=cv2.contourArea)\n",
    "                    mask = np.zeros_like(cleaned)\n",
    "                    cv2.drawContours(mask, [main_contour], -1, 255, -1)\n",
    "\n",
    "                    # Get bounding box with padding\n",
    "                    x, y, w, h = cv2.boundingRect(main_contour)\n",
    "                    pad = max(2, min(w, h) // 10)\n",
    "                    x = max(0, x - pad)\n",
    "                    y = max(0, y - pad)\n",
    "                    w = min(mask.shape[1] - x, w + 2*pad)\n",
    "                    h = min(mask.shape[0] - y, h + 2*pad)\n",
    "                    roi = mask[y:y+h, x:x+w]\n",
    "\n",
    "                    # 4. Center the content\n",
    "                    coords = cv2.findNonZero(roi)\n",
    "                    if coords is not None:\n",
    "                        rx, ry, rw, rh = cv2.boundingRect(coords)\n",
    "                        padding = max(2, min(rw, rh) // 8)\n",
    "                        x_padded = max(0, rx - padding)\n",
    "                        y_padded = max(0, ry - padding)\n",
    "                        w_padded = min(roi.shape[1] - x_padded, rw + 2 * padding)\n",
    "                        h_padded = min(roi.shape[0] - y_padded, rh + 2 * padding)\n",
    "\n",
    "                        roi_h, roi_w = roi.shape\n",
    "                        content_center_x = x_padded + w_padded // 2\n",
    "                        content_center_y = y_padded + h_padded // 2\n",
    "                        roi_center_x = roi_w // 2\n",
    "                        roi_center_y = roi_h // 2\n",
    "\n",
    "                        shift_x = roi_center_x - content_center_x\n",
    "                        shift_y = roi_center_y - content_center_y\n",
    "\n",
    "                        translation_matrix = np.float32([[1, 0, shift_x], [0, 1, shift_y]])\n",
    "                        centered_roi = cv2.warpAffine(roi, translation_matrix, (roi_w, roi_h),\n",
    "                                                       borderMode=cv2.BORDER_CONSTANT,\n",
    "                                                       borderValue=0)\n",
    "\n",
    "                        # 5. Resize to standard template size (200x200)\n",
    "                        resized = cv2.resize(centered_roi, (200, 200), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "                        # Store as-is (white digits on black background, will be inverted during matching)\n",
    "                        templates[digit] = resized\n",
    "                        print(f\"  ✓ Loaded & preprocessed template {digit}\")\n",
    "                    else:\n",
    "                        print(f\"  ✗ Failed to find content in template {digit}\")\n",
    "                else:\n",
    "                    print(f\"  ✗ No contours found in template {digit}\")\n",
    "            else:\n",
    "                print(f\"  ✗ Failed to load template {digit}\")\n",
    "        else:\n",
    "            print(f\"  ✗ Template file not found: {template_path}\")\n",
    "\n",
    "    return templates\n",
    "\n",
    "\n",
    "def extract_and_save_cells(image, output_cells_dir, image_name):\n",
    "    \"\"\"\n",
    "    Extract all 81 cells, enlarge them 2x, and save as individual images\n",
    "    Uses smaller margins to ensure full digit capture before centering\n",
    "    Returns: dictionary of enlarged cell images by position\n",
    "    \"\"\"\n",
    "    os.makedirs(output_cells_dir, exist_ok=True)\n",
    "\n",
    "    h, w = image.shape[:2]\n",
    "    cell_h = h // 9\n",
    "    cell_w = w // 9\n",
    "\n",
    "    cells = {}\n",
    "\n",
    "    # Use very small margins to capture maximum cell content\n",
    "    # This ensures digits near edges are fully included\n",
    "    margin_h = max(2, cell_h // 35)  # Even smaller: 1/35 of cell size\n",
    "    margin_w = max(2, cell_w // 35)  # Even smaller: 1/35 of cell size\n",
    "\n",
    "    for row in range(9):\n",
    "        for col in range(9):\n",
    "            y1 = row * cell_h + margin_h\n",
    "            y2 = (row + 1) * cell_h - margin_h\n",
    "            x1 = col * cell_w + margin_w\n",
    "            x2 = (col + 1) * cell_w - margin_w\n",
    "\n",
    "            cell = image[y1:y2, x1:x2]\n",
    "\n",
    "            # Enlarge cell by 2x for better recognition\n",
    "            enlarged_cell = cv2.resize(cell, None, fx=4.0, fy=4.0, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "            # Save enlarged cell image\n",
    "            cell_filename = f\"cell_r{row}_c{col}.png\"\n",
    "            cell_path = os.path.join(output_cells_dir, cell_filename)\n",
    "            cv2.imwrite(cell_path, enlarged_cell)\n",
    "\n",
    "            cells[(row, col)] = enlarged_cell\n",
    "\n",
    "    print(f\"  → Saved 81 cells to: {output_cells_dir}\")\n",
    "    return cells\n",
    "\n",
    "\n",
    "def preprocess_for_digit_detection(cell):\n",
    "    \"\"\"\n",
    "    Preprocess cell for digit detection\n",
    "    \"\"\"\n",
    "    if cell is None or cell.size == 0:\n",
    "        return None, None\n",
    "\n",
    "    # Convert to grayscale\n",
    "    if len(cell.shape) == 3:\n",
    "        gray = cv2.cvtColor(cell, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = cell.copy()\n",
    "\n",
    "    # Denoise\n",
    "    denoised = cv2.fastNlMeansDenoising(gray, None, h=10, templateWindowSize=7, searchWindowSize=21)\n",
    "\n",
    "    # CLAHE for contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(4, 4))\n",
    "    enhanced = clahe.apply(denoised)\n",
    "\n",
    "    # Try multiple thresholding methods\n",
    "    binary_candidates = []\n",
    "\n",
    "    # Otsu\n",
    "    _, bin1 = cv2.threshold(enhanced, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    binary_candidates.append(bin1)\n",
    "\n",
    "    # Adaptive Gaussian\n",
    "    bin2 = cv2.adaptiveThreshold(enhanced, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                  cv2.THRESH_BINARY_INV, 13, 3)\n",
    "    binary_candidates.append(bin2)\n",
    "\n",
    "    # Adaptive Mean\n",
    "    bin3 = cv2.adaptiveThreshold(enhanced, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                  cv2.THRESH_BINARY_INV, 13, 3)\n",
    "    binary_candidates.append(bin3)\n",
    "\n",
    "    # Select best based on density\n",
    "    best_binary = None\n",
    "    best_score = float('inf')\n",
    "\n",
    "    for binary in binary_candidates:\n",
    "        density = np.sum(binary > 0) / binary.size\n",
    "        if 0.06 < density < 0.40:\n",
    "            score = abs(density - 0.18)\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                best_binary = binary\n",
    "\n",
    "    if best_binary is None:\n",
    "        best_binary = binary_candidates[0]\n",
    "\n",
    "    return enhanced, best_binary\n",
    "\n",
    "\n",
    "def clean_binary(binary):\n",
    "    \"\"\"\n",
    "    Clean binary image with minimal border removal since we use smaller margins\n",
    "    \"\"\"\n",
    "    # Remove noise\n",
    "    kernel = np.ones((2, 2), np.uint8)\n",
    "    cleaned = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "\n",
    "    # Fill gaps\n",
    "    kernel2 = np.ones((3, 3), np.uint8)\n",
    "    cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, kernel2, iterations=1)\n",
    "\n",
    "    # Clear borders very conservatively to preserve edge digits\n",
    "    h, w = cleaned.shape\n",
    "    border = max(1, min(h, w) // 40)  # Very minimal: 1/40 of cell size\n",
    "    cleaned[:border, :] = 0\n",
    "    cleaned[-border:, :] = 0\n",
    "    cleaned[:, :border] = 0\n",
    "    cleaned[:, -border:] = 0\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def is_cell_empty(binary):\n",
    "    \"\"\"\n",
    "    Check if cell is empty\n",
    "    \"\"\"\n",
    "    density = np.sum(binary > 0) / binary.size\n",
    "\n",
    "    if density < 0.015 or density > 0.65:\n",
    "        return True\n",
    "\n",
    "    # Check connected components\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(binary, connectivity=8)\n",
    "\n",
    "    if num_labels <= 1:\n",
    "        return True\n",
    "\n",
    "    areas = stats[1:, cv2.CC_STAT_AREA]\n",
    "    if len(areas) == 0:\n",
    "        return True\n",
    "\n",
    "    largest = np.max(areas)\n",
    "    if largest < binary.size * 0.008 or largest > binary.size * 0.90:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "\n",
    "def find_content_bounds(binary):\n",
    "    \"\"\"\n",
    "    Find the bounding box of content in the cell\n",
    "    Returns: (x, y, width, height) or None if no content\n",
    "    \"\"\"\n",
    "    # Find all non-zero pixels\n",
    "    coords = cv2.findNonZero(binary)\n",
    "\n",
    "    if coords is None or len(coords) == 0:\n",
    "        return None\n",
    "\n",
    "    # Get bounding rectangle\n",
    "    x, y, w, h = cv2.boundingRect(coords)\n",
    "    return (x, y, w, h)\n",
    "\n",
    "\n",
    "def center_content(cell, binary):\n",
    "    \"\"\"\n",
    "    Center the content in the cell by finding content bounds and creating\n",
    "    a centered version with safety padding. Returns centered cell (grayscale).\n",
    "\n",
    "    If cell is empty, returns None.\n",
    "    \"\"\"\n",
    "    if cell is None or cell.size == 0:\n",
    "        return None\n",
    "\n",
    "    # Check if empty\n",
    "    if is_cell_empty(binary):\n",
    "        return None\n",
    "\n",
    "    # Find content bounds\n",
    "    bounds = find_content_bounds(binary)\n",
    "    if bounds is None:\n",
    "        return None\n",
    "\n",
    "    x, y, w, h = bounds\n",
    "\n",
    "    # Get cell dimensions\n",
    "    cell_h, cell_w = cell.shape[:2]\n",
    "\n",
    "    # Add safety padding to content bounds to ensure nothing is cut off\n",
    "    padding = max(2, min(w, h) // 8)\n",
    "    x_padded = max(0, x - padding)\n",
    "    y_padded = max(0, y - padding)\n",
    "    w_padded = min(cell_w - x_padded, w + 2 * padding)\n",
    "    h_padded = min(cell_h - y_padded, h + 2 * padding)\n",
    "\n",
    "    # Calculate shifts needed to center the padded content\n",
    "    content_center_x = x_padded + w_padded // 2\n",
    "    content_center_y = y_padded + h_padded // 2\n",
    "    cell_center_x = cell_w // 2\n",
    "    cell_center_y = cell_h // 2\n",
    "\n",
    "    shift_x = cell_center_x - content_center_x\n",
    "    shift_y = cell_center_y - content_center_y\n",
    "\n",
    "    # Create translation matrix\n",
    "    translation_matrix = np.float32([[1, 0, shift_x], [0, 1, shift_y]])\n",
    "\n",
    "    # Apply translation to center the content\n",
    "    if len(cell.shape) == 3:\n",
    "        gray = cv2.cvtColor(cell, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = cell.copy()\n",
    "\n",
    "    centered = cv2.warpAffine(gray, translation_matrix, (cell_w, cell_h),\n",
    "                              borderMode=cv2.BORDER_CONSTANT,\n",
    "                              borderValue=255)\n",
    "\n",
    "    return centered\n",
    "\n",
    "\n",
    "def extract_digit_component(binary):\n",
    "    \"\"\"\n",
    "    Extract the main digit component\n",
    "    \"\"\"\n",
    "    contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if not contours:\n",
    "        return None, 0\n",
    "\n",
    "    # Find valid contours\n",
    "    valid_contours = []\n",
    "    cell_area = binary.size\n",
    "\n",
    "    for i, cnt in enumerate(contours):\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if cell_area * 0.01 < area < cell_area * 0.85:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            ar = float(w) / h if h > 0 else 0\n",
    "            if w > 4 and h > 6 and 0.1 < ar < 2.0:\n",
    "                valid_contours.append((cnt, area, i))\n",
    "\n",
    "    if not valid_contours:\n",
    "        return None, 0\n",
    "\n",
    "    # Get largest valid contour\n",
    "    main_contour, _, main_idx = max(valid_contours, key=lambda x: x[1])\n",
    "\n",
    "    # Create mask\n",
    "    mask = np.zeros_like(binary)\n",
    "    cv2.drawContours(mask, [main_contour], -1, 255, -1)\n",
    "\n",
    "    # Get bounding box\n",
    "    x, y, w, h = cv2.boundingRect(main_contour)\n",
    "    pad = max(2, min(w, h) // 10)\n",
    "    x = max(0, x - pad)\n",
    "    y = max(0, y - pad)\n",
    "    w = min(mask.shape[1] - x, w + 2*pad)\n",
    "    h = min(mask.shape[0] - y, h + 2*pad)\n",
    "\n",
    "    roi = mask[y:y+h, x:x+w]\n",
    "\n",
    "    # Count holes\n",
    "    holes = 0\n",
    "    if hierarchy is not None:\n",
    "        for i, h_info in enumerate(hierarchy[0]):\n",
    "            if h_info[3] == main_idx:\n",
    "                hole_area = cv2.contourArea(contours[i])\n",
    "                if hole_area > cell_area * 0.002:\n",
    "                    holes += 1\n",
    "\n",
    "    return roi, holes\n",
    "\n",
    "\n",
    "def compute_digit_features(roi):\n",
    "    \"\"\"\n",
    "    Extract features from digit ROI\n",
    "    \"\"\"\n",
    "    if roi is None or roi.size == 0:\n",
    "        return None\n",
    "\n",
    "    h, w = roi.shape\n",
    "    aspect_ratio = float(w) / h if h > 0 else 0\n",
    "\n",
    "    # Divide into regions\n",
    "    h_third = max(1, h // 3)\n",
    "    w_third = max(1, w // 3)\n",
    "\n",
    "    top = roi[:h_third, :]\n",
    "    middle = roi[h_third:2*h_third, :]\n",
    "    bottom = roi[2*h_third:, :]\n",
    "    left = roi[:, :w_third]\n",
    "    center = roi[:, w_third:2*w_third]\n",
    "    right = roi[:, 2*w_third:]\n",
    "\n",
    "    def density(region):\n",
    "        return np.sum(region > 0) / region.size if region.size > 0 else 0\n",
    "\n",
    "    return {\n",
    "        'ar': aspect_ratio,\n",
    "        'top': density(top),\n",
    "        'mid': density(middle),\n",
    "        'bot': density(bottom),\n",
    "        'left': density(left),\n",
    "        'center': density(center),\n",
    "        'right': density(right)\n",
    "    }\n",
    "\n",
    "\n",
    "def match_template(roi, templates):\n",
    "    \"\"\"\n",
    "    Match ROI with templates - centers content before comparison\n",
    "    \"\"\"\n",
    "    if roi is None or roi.size == 0:\n",
    "        return {}\n",
    "\n",
    "    # Center the ROI content before resizing to match template format\n",
    "    # Find content bounds in ROI\n",
    "    coords = cv2.findNonZero(roi)\n",
    "    if coords is None or len(coords) == 0:\n",
    "        return {}\n",
    "\n",
    "    x, y, w, h = cv2.boundingRect(coords)\n",
    "\n",
    "    # Extract content with padding\n",
    "    padding = max(2, min(w, h) // 8)\n",
    "    x_padded = max(0, x - padding)\n",
    "    y_padded = max(0, y - padding)\n",
    "    w_padded = min(roi.shape[1] - x_padded, w + 2 * padding)\n",
    "    h_padded = min(roi.shape[0] - y_padded, h + 2 * padding)\n",
    "\n",
    "    # Create centered version\n",
    "    roi_h, roi_w = roi.shape\n",
    "    content_center_x = x_padded + w_padded // 2\n",
    "    content_center_y = y_padded + h_padded // 2\n",
    "    roi_center_x = roi_w // 2\n",
    "    roi_center_y = roi_h // 2\n",
    "\n",
    "    shift_x = roi_center_x - content_center_x\n",
    "    shift_y = roi_center_y - content_center_y\n",
    "\n",
    "    # Create translation matrix\n",
    "    translation_matrix = np.float32([[1, 0, shift_x], [0, 1, shift_y]])\n",
    "\n",
    "    # Apply translation to center the content\n",
    "    centered_roi = cv2.warpAffine(roi, translation_matrix, (roi_w, roi_h),\n",
    "                                   borderMode=cv2.BORDER_CONSTANT,\n",
    "                                   borderValue=0)\n",
    "\n",
    "    # Now resize the centered ROI to match template size\n",
    "    # Get template size from first template\n",
    "    template_size = list(templates.values())[0].shape\n",
    "    resized = cv2.resize(centered_roi, (template_size[1], template_size[0]),\n",
    "                        interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    # Both ROI and templates are now preprocessed identically:\n",
    "    # - Binary (white digits on black background)\n",
    "    # - Centered\n",
    "    # - Same size\n",
    "    # NO NEED to invert since both have the same format!\n",
    "\n",
    "    scores = {}\n",
    "    for digit, template in templates.items():\n",
    "        result = cv2.matchTemplate(resized, template, cv2.TM_CCOEFF_NORMED)\n",
    "        scores[digit] = result[0][0]\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def classify_by_rules(features, holes):\n",
    "    \"\"\"\n",
    "    Rule-based classification\n",
    "    \"\"\"\n",
    "    if features is None:\n",
    "        return 0, 0.0\n",
    "\n",
    "    ar = features['ar']\n",
    "    top = features['top']\n",
    "    mid = features['mid']\n",
    "    bot = features['bot']\n",
    "    left = features['left']\n",
    "    right = features['right']\n",
    "\n",
    "    # Holes give strong clues\n",
    "    if holes == 2:\n",
    "        return 8, 0.98\n",
    "\n",
    "    elif holes == 1:\n",
    "        if ar < 0.55:  # Narrow\n",
    "            if top > bot * 1.1:\n",
    "                return 9, 0.92\n",
    "            else:\n",
    "                return 6, 0.92\n",
    "        else:  # Wider\n",
    "            if mid > (top + bot) / 2 * 1.1:\n",
    "                return 4, 0.88\n",
    "            else:\n",
    "                return 0, 0.85\n",
    "\n",
    "    # No holes - improved rules for 5, 6, 7, 9\n",
    "    else:\n",
    "        # Check for 7 first - it has very distinctive top-heavy distribution\n",
    "        if top > bot * 1.8:  # Strong top-heavy pattern\n",
    "            return 7, 0.92\n",
    "\n",
    "        if ar < 0.35:\n",
    "            return 1, 0.95\n",
    "\n",
    "        elif ar < 0.60:\n",
    "            if top > bot * 1.3:  # Relaxed threshold for 7\n",
    "                return 7, 0.87\n",
    "            else:\n",
    "                return 1, 0.85\n",
    "\n",
    "        else:  # Wider digits (ar >= 0.60)\n",
    "            # Check for 7 with looser AR constraint\n",
    "            if top > bot * 1.5 and mid < (top + bot) / 2:\n",
    "                return 7, 0.85\n",
    "            # Check for 5 - top heavy, more left-heavy\n",
    "            elif top > bot * 1.1 and left > right * 1.1:\n",
    "                return 5, 0.82\n",
    "            # Check for 6 - should have been caught by holes, but backup\n",
    "            elif bot > top * 1.1 and left > right:\n",
    "                return 6, 0.78\n",
    "            # Check for 3 - right heavy\n",
    "            elif right > left * 1.15:\n",
    "                return 3, 0.78\n",
    "            # Check for 2 - bottom heavy\n",
    "            elif bot > top * 1.2:\n",
    "                return 2, 0.78\n",
    "            else:\n",
    "                return 3, 0.65\n",
    "\n",
    "\n",
    "def recognize_digit_cv(cell, templates):\n",
    "    \"\"\"\n",
    "    Recognize digit using CV algorithms only\n",
    "    Improved fusion between template matching and rule-based classification\n",
    "    \"\"\"\n",
    "    if cell is None or cell.size == 0:\n",
    "        return 0\n",
    "\n",
    "    # Initial preprocess to check if empty\n",
    "    enhanced, binary = preprocess_for_digit_detection(cell)\n",
    "    if binary is None:\n",
    "        return 0\n",
    "\n",
    "    # Clean\n",
    "    binary = clean_binary(binary)\n",
    "\n",
    "    # Check if empty\n",
    "    if is_cell_empty(binary):\n",
    "        return 0\n",
    "\n",
    "    # Center the content in the cell (only if not empty)\n",
    "    centered_cell = center_content(cell, binary)\n",
    "    if centered_cell is None:\n",
    "        return 0\n",
    "\n",
    "    # Re-preprocess the centered cell\n",
    "    enhanced, binary = preprocess_for_digit_detection(centered_cell)\n",
    "    if binary is None:\n",
    "        return 0\n",
    "\n",
    "    # Clean again\n",
    "    binary = clean_binary(binary)\n",
    "\n",
    "    # Extract digit component from centered image\n",
    "    roi, holes = extract_digit_component(binary)\n",
    "    if roi is None:\n",
    "        return 0\n",
    "\n",
    "    # Get features\n",
    "    features = compute_digit_features(roi)\n",
    "\n",
    "    # Template matching\n",
    "    template_scores = match_template(roi, templates)\n",
    "\n",
    "    # Rule-based classification\n",
    "    rule_digit, rule_conf = classify_by_rules(features, holes)\n",
    "\n",
    "    # Improved fusion logic - prioritize template matching more strongly\n",
    "    if template_scores:\n",
    "        # Get top 3 template scores\n",
    "        sorted_scores = sorted(template_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        best_template = sorted_scores[0][0]\n",
    "        best_score = sorted_scores[0][1]\n",
    "        second_best = sorted_scores[1] if len(sorted_scores) > 1 else (0, 0)\n",
    "        third_best = sorted_scores[2] if len(sorted_scores) > 2 else (0, 0)\n",
    "\n",
    "        # Very strong template match - almost always trust it\n",
    "        if best_score > 0.60:\n",
    "            return best_template\n",
    "\n",
    "        # Strong template match\n",
    "        elif best_score > 0.50:\n",
    "            # If much better than second best, trust it\n",
    "            if best_score - second_best[1] > 0.10:\n",
    "                return best_template\n",
    "            # If close to second best but agrees with rules, trust it\n",
    "            elif best_template == rule_digit:\n",
    "                return best_template\n",
    "            # Otherwise still prefer template unless rules are very confident\n",
    "            elif rule_conf > 0.90:\n",
    "                return rule_digit\n",
    "            else:\n",
    "                return best_template\n",
    "\n",
    "        # Good template match\n",
    "        elif best_score > 0.40:\n",
    "            # Clear winner and decent confidence\n",
    "            if best_score - second_best[1] > 0.12:\n",
    "                return best_template\n",
    "            # Agreement with rules\n",
    "            elif best_template == rule_digit:\n",
    "                return best_template\n",
    "            # Check if second or third best agrees with rules\n",
    "            elif second_best[0] == rule_digit and second_best[1] > 0.35:\n",
    "                return rule_digit\n",
    "            elif third_best[0] == rule_digit and third_best[1] > 0.32 and rule_conf > 0.85:\n",
    "                return rule_digit\n",
    "            # Template score is better than rule confidence\n",
    "            elif best_score > rule_conf + 0.10:\n",
    "                return best_template\n",
    "            # High rule confidence\n",
    "            elif rule_conf > 0.85:\n",
    "                return rule_digit\n",
    "            else:\n",
    "                return best_template\n",
    "\n",
    "        # Moderate template match\n",
    "        elif best_score > 0.30:\n",
    "            # High rule confidence, go with rules\n",
    "            if rule_conf > 0.80:\n",
    "                return rule_digit\n",
    "            # Check if any top 3 templates agree with rules\n",
    "            elif rule_digit in [sorted_scores[i][0] for i in range(min(3, len(sorted_scores)))]:\n",
    "                # Find the matching score\n",
    "                for digit, score in sorted_scores[:3]:\n",
    "                    if digit == rule_digit:\n",
    "                        # If it's reasonably high, trust the agreement\n",
    "                        if score > 0.25:\n",
    "                            return rule_digit\n",
    "                        break\n",
    "                return best_template\n",
    "            # Template is clearly better\n",
    "            elif best_score > rule_conf + 0.15:\n",
    "                return best_template\n",
    "            else:\n",
    "                return rule_digit\n",
    "\n",
    "        # Weak template match - trust rules if confident\n",
    "        else:\n",
    "            if rule_conf > 0.70:\n",
    "                return rule_digit\n",
    "            elif best_score > 0.20:\n",
    "                return best_template\n",
    "            else:\n",
    "                return rule_digit\n",
    "\n",
    "    return rule_digit\n",
    "\n",
    "\n",
    "def save_templates_as_images(templates, output_dir):\n",
    "    \"\"\"\n",
    "    Save all digit templates as images for visualization\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for digit, template in templates.items():\n",
    "        # Enlarge template for better visibility\n",
    "        enlarged = cv2.resize(template, (112, 112), interpolation=cv2.INTER_NEAREST)\n",
    "        template_path = os.path.join(output_dir, f\"template_{digit}.png\")\n",
    "        cv2.imwrite(template_path, enlarged)\n",
    "\n",
    "    print(f\"  ✓ Saved {len(templates)} templates to: {output_dir}\")\n",
    "\n",
    "\n",
    "def process_sudoku_image(image_path, output_base_dir, image_index, templates):\n",
    "    \"\"\"\n",
    "    Process a single Sudoku image:\n",
    "    1. Extract and save all 81 cells\n",
    "    2. Recognize digits using CV\n",
    "    3. Create and save the Sudoku array\n",
    "    \"\"\"\n",
    "    # Create output directories\n",
    "    image_name = os.path.splitext(os.path.basename(image_path))[0]\n",
    "    image_output_dir = os.path.join(output_base_dir, f\"image_{image_index:02d}_{image_name}\")\n",
    "    cells_dir = os.path.join(image_output_dir, \"cells\")\n",
    "\n",
    "    os.makedirs(image_output_dir, exist_ok=True)\n",
    "    os.makedirs(cells_dir, exist_ok=True)\n",
    "\n",
    "    # Load image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"  ✗ Failed to load image\")\n",
    "        return None\n",
    "\n",
    "    print(f\"\\n[Image {image_index}] {image_name}\")\n",
    "\n",
    "    # Extract and save all cells\n",
    "    cells = extract_and_save_cells(image, cells_dir, image_name)\n",
    "\n",
    "    # Recognize digits\n",
    "    print(f\"  → Recognizing digits using CV algorithms...\")\n",
    "    sudoku_array = np.zeros((9, 9), dtype=int)\n",
    "\n",
    "    for row in range(9):\n",
    "        for col in range(9):\n",
    "            cell = cells[(row, col)]\n",
    "            digit = recognize_digit_cv(cell, templates)\n",
    "            sudoku_array[row, col] = digit\n",
    "\n",
    "    num_digits = np.sum(sudoku_array != 0)\n",
    "    print(f\"  → Detected {num_digits} digits\")\n",
    "\n",
    "    # Print array\n",
    "    print(f\"  → Sudoku Grid:\")\n",
    "    for row in sudoku_array:\n",
    "        print(f\"     {' '.join(str(d) if d != 0 else '.' for d in row)}\")\n",
    "\n",
    "    # Save array as text file\n",
    "    array_path = os.path.join(image_output_dir, \"sudoku_array.txt\")\n",
    "    with open(array_path, 'w') as f:\n",
    "        f.write(f\"Sudoku Grid from: {image_name}\\n\")\n",
    "        f.write(f\"Detected {num_digits} digits\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "        f.write(\"Grid (. = empty):\\n\")\n",
    "        for row in sudoku_array:\n",
    "            f.write(' '.join(str(d) if d != 0 else '.' for d in row) + '\\n')\n",
    "        f.write(\"\\n\" + \"=\" * 50 + \"\\n\\n\")\n",
    "        f.write(\"Python array:\\n\")\n",
    "        f.write(str(sudoku_array.tolist()) + \"\\n\")\n",
    "\n",
    "    print(f\"  ✓ Saved array: {array_path}\")\n",
    "\n",
    "    # Draw and save grid with lines\n",
    "    h, w = image.shape[:2]\n",
    "    cell_size = 60\n",
    "    size = cell_size * 9\n",
    "\n",
    "    if len(image.shape) == 2:\n",
    "        resized = cv2.resize(image, (size, size))\n",
    "        grid_img = cv2.cvtColor(resized, cv2.COLOR_GRAY2BGR)\n",
    "    else:\n",
    "        grid_img = cv2.resize(image, (size, size))\n",
    "\n",
    "    # Draw grid lines\n",
    "    for i in range(10):\n",
    "        thickness = 3 if i % 3 == 0 else 1\n",
    "        color = (0, 0, 0) if i % 3 == 0 else (100, 100, 100)\n",
    "        y = i * cell_size\n",
    "        cv2.line(grid_img, (0, y), (size, y), color, thickness)\n",
    "        x = i * cell_size\n",
    "        cv2.line(grid_img, (x, 0), (x, size), color, thickness)\n",
    "\n",
    "    grid_path = os.path.join(image_output_dir, \"sudoku_grid.jpg\")\n",
    "    cv2.imwrite(grid_path, grid_img)\n",
    "    print(f\"  ✓ Saved grid: {grid_path}\")\n",
    "\n",
    "    # Create empty grid template\n",
    "    empty_grid = np.ones((size, size, 3), dtype=np.uint8) * 255\n",
    "    for i in range(10):\n",
    "        thickness = 3 if i % 3 == 0 else 1\n",
    "        color = (0, 0, 0) if i % 3 == 0 else (150, 150, 150)\n",
    "        y = i * cell_size\n",
    "        cv2.line(empty_grid, (0, y), (size, y), color, thickness)\n",
    "        x = i * cell_size\n",
    "        cv2.line(empty_grid, (x, 0), (x, size), color, thickness)\n",
    "\n",
    "    empty_path = os.path.join(image_output_dir, \"empty_grid.jpg\")\n",
    "    cv2.imwrite(empty_path, empty_grid)\n",
    "    print(f\"  ✓ Saved empty grid: {empty_path}\")\n",
    "\n",
    "    print(\"  → Solving detected Sudoku...\")\n",
    "    solved_json_path = os.path.join(image_output_dir, \"sudoku_solved.json\")\n",
    "    solved_ok, solved_grid = try_solve_grid(sudoku_array.tolist(), solved_json_path)\n",
    "    if solved_ok:\n",
    "        print(\"  ✓ Sudoku solved during pipeline\")\n",
    "    else:\n",
    "        print(\"  ✗ Sudoku could not be solved\")\n",
    "\n",
    "    return {\n",
    "        'image_name': image_name,\n",
    "        'output_dir': image_output_dir,\n",
    "        'cells_dir': cells_dir,\n",
    "        'array': sudoku_array,\n",
    "        'num_digits': num_digits,\n",
    "        'array_path': array_path,\n",
    "        'grid_path': grid_path\n",
    "    }\n",
    "\n",
    "\n",
    "def process_all_sudoku_images(input_dir, output_dir, templates):\n",
    "    \"\"\"\n",
    "    Process all Sudoku images in the input directory\n",
    "    \"\"\"\n",
    "\n",
    "    # Get all images\n",
    "    image_files = sorted([f for f in os.listdir(input_dir) if f.endswith('_clean.png')])\n",
    "\n",
    "    if not image_files:\n",
    "        print(f\"No images found in {input_dir}\")\n",
    "        return []\n",
    "\n",
    "    print(\"=\" * 70)\n",
    "    print(\"SUDOKU OCR WITH CELL EXTRACTION\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"Input: {input_dir}\")\n",
    "    print(f\"Output: {output_dir}\")\n",
    "    print(f\"Found {len(image_files)} images to process\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for idx, filename in enumerate(image_files, 1):\n",
    "        image_path = os.path.join(input_dir, filename)\n",
    "        result = process_sudoku_image(image_path, output_dir, idx, templates)\n",
    "\n",
    "        if result:\n",
    "            results.append(result)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(f\"✓ PROCESSING COMPLETE\")\n",
    "    print(f\"  Processed: {len(results)}/{len(image_files)} images\")\n",
    "    print(f\"  Output directory: {output_dir}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    # Print summary\n",
    "    print(\"\\nSUMMARY OF ALL GRIDS:\")\n",
    "    print(\"=\" * 70)\n",
    "    for idx, result in enumerate(results, 1):\n",
    "        print(f\"\\n[{idx}] {result['image_name']}\")\n",
    "        print(f\"    Digits detected: {result['num_digits']}/81\")\n",
    "        print(f\"    Output: {result['output_dir']}\")\n",
    "        print(f\"    Cells: {result['cells_dir']}\")\n",
    "        print(f\"    Grid:\")\n",
    "        for row in result['array']:\n",
    "            print(f\"      {' '.join(str(d) if d != 0 else '.' for d in row)}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Load templates from template_centered_resized directory\n",
    "templates_dir = '/content/drive/MyDrive/Computer Vision Final/templates_centered_resized'\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"Loading templates from template_centered_resized directory...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "templates = load_templates_from_directory(templates_dir)\n",
    "\n",
    "if not templates:\n",
    "    print(\"\\n✗ No templates loaded! Make sure to run the template creation cell first.\")\n",
    "else:\n",
    "    print(f\"\\n✓ Successfully loaded {len(templates)} templates\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "\n",
    "    # Execute the complete processing\n",
    "    input_dir = '/content/drive/MyDrive/Computer Vision Final/sudoku_preprocessed_final'\n",
    "    output_dir = '/content/drive/MyDrive/Computer Vision Final/sudoku_ocr_results'\n",
    "\n",
    "    results = process_all_sudoku_images(input_dir, output_dir, templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
